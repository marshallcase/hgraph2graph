{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e54f552-f2a7-43f3-bca8-89abea847cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcase/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#train with seperate encoder and predictor models bc I can't get transfer learning to work\n",
    "import math, random, sys\n",
    "sys.path.insert(0, '/home/marcase/hgraph2graph/')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import networkx as nx\n",
    "import rdkit\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "from hgraph import *\n",
    "from hgraph.inc_graph import *\n",
    "from hgraph.encoder import *\n",
    "import matplotlib.pyplot as plt\n",
    "from hgraph.predict import HierPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e3a62cb-0221-4f45-8d17-5f94673f21b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C',\n",
       " 'C1=CC=CC=C1',\n",
       " 'C1=CNC=C1',\n",
       " 'C1=CNC=N1',\n",
       " 'C1CCNC1',\n",
       " 'C1CNCCNCCNCCNCCNCCNCCNCCNCCNCCNCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCNCCNCCNCCNCCNCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCNCCNCCNCCNCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCNCCNCCNCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCNCCNCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCNCCNCCNCCSCCCSCCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCNCCNCCNCCSCCCSCCNCCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCNCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCNCCNCCSCCCSCCCNCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCNCCNCCSCCCSCCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCNCCNCCSCCCSCCNCCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCNCCSCCCSCCCNCCNCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCNCCSCCCSCCCNCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCNCCSCCCSCCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCNCCSCCCSCCNCCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCSCCCSCCCNCCNCCNCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCSCCCSCCCNCCNCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCSCCCSCCCNCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCSCCCSCCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCSCCCSCCNCCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCNCCSCCCSCCNCCNCCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCSCCCSCCCNCCNCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCSCCCSCCCNCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCSCCCSCCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCSCCCSCCNCCCSCCCSC1',\n",
       " 'C1CNCCNCCNCCSCCCSCCNCCNCCCSCCCSC1',\n",
       " 'C1CNCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCSCCCSCCCNCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCSCCCSCCCNCCSCCCSC1',\n",
       " 'C1CNCCNCCSCCCSCCNCCCSCCCSC1',\n",
       " 'C1CNCCNCCSCCCSCCNCCNCCCSCCCSC1',\n",
       " 'C1CNCCSCCCSC1',\n",
       " 'C1CNCCSCCCSCCCNCCSCCCSC1',\n",
       " 'C1CNCCSCCCSCCNCCCSCCCSC1',\n",
       " 'C=N',\n",
       " 'C=O',\n",
       " 'CC',\n",
       " 'CN',\n",
       " 'CO',\n",
       " 'CS',\n",
       " 'N']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = '/home/marcase/hgraph2graph/data/chembl/cyclic_peptide_vocab.txt'\n",
    "vocab = [x.strip(\"\\r\\n \").split() for x in open(vocab)]\n",
    "vocab = PairVocab(vocab)\n",
    "vocab.vocab[21][0]\n",
    "vocab.hvocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3613058a-77d0-4bb1-895d-475b38d1ef42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcase/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    train = '/home/marcase/hgraph2graph/predict/preprocessed_master/preprocessed_train/'\n",
    "    train_labels = '/home/marcase/hgraph2graph/predict/preprocessed_master/preprocessed_train_labels/'\n",
    "    test = '/home/marcase/hgraph2graph/predict/preprocessed_master/preprocessed_test/'\n",
    "    test_labels = '/home/marcase/hgraph2graph/predict/preprocessed_master/preprocessed_test_labels/'\n",
    "    vocab = vocab\n",
    "    save_dir = 'test/'\n",
    "    atom_vocab = common_atom_vocab\n",
    "    load_model = None\n",
    "    seed = 7\n",
    "    rnn_type = 'LSTM'\n",
    "    hidden_size=125\n",
    "    embed_size=250\n",
    "    batch_size=8\n",
    "    latent_size=32\n",
    "    depthT=15\n",
    "    depthG=15\n",
    "    diterT=1\n",
    "    diterG=3\n",
    "    dropout=0.2\n",
    "    lr = 1e-2\n",
    "    clip_norm=5.0\n",
    "    step_beta=0.001\n",
    "    max_beta=1.0\n",
    "    warmup=10000\n",
    "    kl_anneal_iter=2000\n",
    "    epoch=2000\n",
    "    anneal_rate=0.9\n",
    "    anneal_iter=25000\n",
    "    print_iter=50\n",
    "    save_iter=1000000\n",
    "    model = '/home/marcase/hgraph2graph/ckpt/cyclic_peptide_pretrained/model.ckpt.110000'\n",
    "    load_model = True\n",
    "    nsample = 1\n",
    "    label_size = 2\n",
    "    \n",
    "args=Args()\n",
    "\n",
    "encoder = HierVAE(args).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc66962-8eab-4300-abca-7c32e7a39562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HierPredict(\n",
       "  (ff1): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (ff2): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (ff3): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=2, bias=True)\n",
       "    (1): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HierPredict(args).cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c4eaa9e-c924-4c36-a530-eaaf8bcb1727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuing from checkpoint /home/marcase/hgraph2graph/ckpt/cyclic_peptide_pretrained/model.ckpt.110000\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "\n",
    "for param in encoder.parameters():\n",
    "    if param.dim() == 1:\n",
    "        nn.init.constant_(param, 0)\n",
    "    else:\n",
    "        nn.init.xavier_normal_(param)\n",
    "        \n",
    "for param in model.parameters():\n",
    "    if param.dim() == 1:\n",
    "        nn.init.constant_(param, 0)\n",
    "    else:\n",
    "        nn.init.xavier_normal_(param)        \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, args.anneal_rate)\n",
    "\n",
    "if args.load_model:\n",
    "    print('continuing from checkpoint ' + args.model)\n",
    "    model_state, optimizer_state, total_step, beta = torch.load(args.model)\n",
    "    \n",
    "    encoder.load_state_dict(model_state)\n",
    "\n",
    "else:\n",
    "    total_step = beta = 0\n",
    "\n",
    "param_norm = lambda m: math.sqrt(sum([p.norm().item() ** 2 for p in m.parameters()]))\n",
    "grad_norm = lambda m: math.sqrt(sum([p.grad.norm().item() ** 2 for p in m.parameters() if p.grad is not None]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78836dcc-d9c0-4239-9652-593fd78a7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meters = np.array([])\n",
    "meters_list = list(meters)\n",
    "validation_list = list()\n",
    "total_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3568ca1b-ce78-4257-8441-3cf4cfc92bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50] Beta: 0.050, loss: 0.687, accuracy: 0.625, PNorm: 8.64, GNorm: 0.18\n",
      "[100] Beta: 0.050, loss: 0.777, accuracy: 0.375, PNorm: 8.80, GNorm: 0.81\n",
      "[150] Beta: 0.050, loss: 0.910, accuracy: 0.375, PNorm: 9.18, GNorm: 0.40\n",
      "[200] Beta: 0.050, loss: 0.630, accuracy: 0.875, PNorm: 9.41, GNorm: 0.51\n",
      "[250] Beta: 0.050, loss: 0.597, accuracy: 0.750, PNorm: 9.67, GNorm: 0.54\n",
      "[300] Beta: 0.050, loss: 0.685, accuracy: 0.500, PNorm: 9.84, GNorm: 0.49\n",
      "Accuracy on validation set: 0.610\n",
      "[350] Beta: 0.050, loss: 0.816, accuracy: 0.500, PNorm: 10.04, GNorm: 0.24\n",
      "[400] Beta: 0.050, loss: 0.693, accuracy: 0.625, PNorm: 10.29, GNorm: 0.30\n",
      "[450] Beta: 0.050, loss: 0.773, accuracy: 0.500, PNorm: 10.33, GNorm: 0.27\n",
      "[500] Beta: 0.050, loss: 0.859, accuracy: 0.375, PNorm: 10.65, GNorm: 0.38\n",
      "[550] Beta: 0.050, loss: 0.508, accuracy: 0.875, PNorm: 10.83, GNorm: 0.35\n",
      "[600] Beta: 0.050, loss: 0.710, accuracy: 0.625, PNorm: 11.09, GNorm: 0.26\n",
      "[650] Beta: 0.050, loss: 0.705, accuracy: 0.500, PNorm: 11.27, GNorm: 0.50\n",
      "Accuracy on validation set: 0.611\n",
      "[700] Beta: 0.050, loss: 0.689, accuracy: 0.625, PNorm: 11.39, GNorm: 0.31\n",
      "[750] Beta: 0.050, loss: 0.553, accuracy: 0.750, PNorm: 11.60, GNorm: 0.17\n",
      "[800] Beta: 0.050, loss: 0.618, accuracy: 0.750, PNorm: 11.63, GNorm: 0.28\n",
      "[850] Beta: 0.050, loss: 0.593, accuracy: 0.750, PNorm: 11.83, GNorm: 0.19\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.epoch):\n",
    "    random.seed(args.seed)\n",
    "    dataset_x = DataFolder(args.train, args.batch_size,shuffle = False)\n",
    "    dataset_y = DataFolder(args.train_labels, args.batch_size,shuffle = False)\n",
    "    dataset_x.data_files = ['tensors-'+str(i)+'.pkl' for i in range(len(dataset_x.data_files))]\n",
    "    dataset_y.data_files = ['tensors_labels-'+str(i)+'.pkl' for i in range(len(dataset_y.data_files))]\n",
    "    model.train()\n",
    "    for batch_x,batch_y in zip(dataset_x,dataset_y):\n",
    "        total_step += 1\n",
    "        model.zero_grad()\n",
    "        latent = encoder(*batch_x, beta=beta,decode=False) \n",
    "        y_pred = model(latent)\n",
    "        y_true = torch.Tensor([int(y) for y in batch_y]).cuda()\n",
    "        y_true = y_true.type(torch.LongTensor).cuda()\n",
    "        loss = criterion(y_pred,y_true)\n",
    "        accuracy = torch.sum(torch.argmax(y_pred, dim=1).cuda() == y_true)/len(y_true)\n",
    "        # loss = Variable(loss, requires_grad = True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        meters = np.array([loss.item(),accuracy.cpu()])\n",
    "        meters_list.append(meters)\n",
    "\n",
    "        if total_step % args.print_iter == 0:\n",
    "            print(\"[%d] Beta: %.3f, loss: %.3f, accuracy: %.3f, PNorm: %.2f, GNorm: %.2f\" % (total_step, beta, meters[0], meters[1], param_norm(model), grad_norm(model)))\n",
    "            sys.stdout.flush()\n",
    "            meters *= 0\n",
    "        \n",
    "        if total_step % args.save_iter == 0:\n",
    "            ckpt = (model.state_dict(), optimizer.state_dict(), total_step, beta)\n",
    "            torch.save(ckpt, os.path.join(args.save_dir, f\"model.ckpt.{total_step}\"))\n",
    "\n",
    "        if total_step % args.anneal_iter == 0:\n",
    "            scheduler.step()\n",
    "            print(\"learning rate: %.6f\" % scheduler.get_lr()[0])\n",
    "\n",
    "        if total_step >= args.warmup and total_step % args.kl_anneal_iter == 0:\n",
    "            beta = min(args.max_beta, beta + args.step_beta)\n",
    "    \n",
    "    #\"validation\" set\n",
    "    model.eval()\n",
    "    dataset_x = DataFolder(args.test, args.batch_size,shuffle = False)\n",
    "    dataset_y = DataFolder(args.test_labels, args.batch_size,shuffle = False)\n",
    "    dataset_x.data_files = ['tensors-'+str(i)+'.pkl' for i in range(len(dataset_x.data_files))]\n",
    "    dataset_y.data_files = ['tensors_labels-'+str(i)+'.pkl' for i in range(len(dataset_y.data_files))]\n",
    "    random.seed()\n",
    "    i=0\n",
    "    accuracy_list = list()\n",
    "    for batch_x,batch_y in zip(dataset_x,dataset_y):\n",
    "        batch_x0 = batch_x\n",
    "        batch_y0 = batch_y\n",
    "        latent = encoder(*batch_x, beta=beta,decode=False) \n",
    "        y_pred = model(latent)\n",
    "        y_pred = torch.argmax(y_pred, dim=1)\n",
    "        y_true = torch.Tensor([int(y) for y in batch_y0]).cuda()\n",
    "        y_true = y_true.type(torch.LongTensor).cuda()\n",
    "        accuracy_list.append((torch.sum(y_pred == y_true)/len(y_pred)).item())\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    print('Accuracy on validation set: %.3f' % np.average(accuracy_list))\n",
    "    validation_list.append((torch.sum(y_pred == y_true)/len(y_pred)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eeb6c4ca-e9b3-49b0-b67b-c900a620ff18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tensors-0.pkl',\n",
       " 'tensors-1.pkl',\n",
       " 'tensors-2.pkl',\n",
       " 'tensors-3.pkl',\n",
       " 'tensors-4.pkl',\n",
       " 'tensors-5.pkl',\n",
       " 'tensors-6.pkl',\n",
       " 'tensors-7.pkl',\n",
       " 'tensors-8.pkl',\n",
       " 'tensors-9.pkl',\n",
       " 'tensors-10.pkl',\n",
       " 'tensors-11.pkl',\n",
       " 'tensors-12.pkl',\n",
       " 'tensors-13.pkl',\n",
       " 'tensors-14.pkl',\n",
       " 'tensors-15.pkl',\n",
       " 'tensors-16.pkl',\n",
       " 'tensors-17.pkl',\n",
       " 'tensors-18.pkl',\n",
       " 'tensors-19.pkl',\n",
       " 'tensors-20.pkl',\n",
       " 'tensors-21.pkl',\n",
       " 'tensors-22.pkl',\n",
       " 'tensors-23.pkl',\n",
       " 'tensors-24.pkl',\n",
       " 'tensors-25.pkl',\n",
       " 'tensors-26.pkl',\n",
       " 'tensors-27.pkl',\n",
       " 'tensors-28.pkl',\n",
       " 'tensors-29.pkl',\n",
       " 'tensors-30.pkl',\n",
       " 'tensors-31.pkl',\n",
       " 'tensors-32.pkl',\n",
       " 'tensors-33.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x = DataFolder(args.train, args.batch_size,shuffle = False)\n",
    "dataset_x.data_files = ['tensors-'+str(i)+'.pkl' for i in range(len(dataset_x.data_files))]\n",
    "dataset_x.data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a107c508-eb8f-4634-8e73-0c575cfcda3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1701, 0.8299],\n",
       "        [0.1210, 0.8790],\n",
       "        [0.4298, 0.5702],\n",
       "        [0.4205, 0.5795],\n",
       "        [0.3272, 0.6728],\n",
       "        [0.1508, 0.8492],\n",
       "        [0.2056, 0.7944],\n",
       "        [0.1318, 0.8682],\n",
       "        [0.2318, 0.7682],\n",
       "        [0.2574, 0.7426],\n",
       "        [0.3937, 0.6063],\n",
       "        [0.3240, 0.6760],\n",
       "        [0.2951, 0.7049],\n",
       "        [0.2564, 0.7436],\n",
       "        [0.3607, 0.6393],\n",
       "        [0.2876, 0.7124],\n",
       "        [0.4141, 0.5859],\n",
       "        [0.2326, 0.7674],\n",
       "        [0.1597, 0.8403],\n",
       "        [0.3544, 0.6456],\n",
       "        [0.2972, 0.7028],\n",
       "        [0.3681, 0.6319],\n",
       "        [0.3508, 0.6492],\n",
       "        [0.3615, 0.6385],\n",
       "        [0.3248, 0.6752],\n",
       "        [0.1423, 0.8577],\n",
       "        [0.1934, 0.8066],\n",
       "        [0.1963, 0.8037],\n",
       "        [0.3888, 0.6112],\n",
       "        [0.2786, 0.7214],\n",
       "        [0.2361, 0.7639],\n",
       "        [0.3717, 0.6283]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(latent)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96a56d6-0482-4e9c-862c-4c938cc23c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hgraph-rdkit",
   "language": "python",
   "name": "hgraph-rdkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
