{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bca8c96-4408-478f-a668-04f728d17637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training test for prediction capabilities \n",
    "import math, random, sys\n",
    "sys.path.insert(0, '/home/marcase/hgraph2graph/')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import networkx as nx\n",
    "import rdkit\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "from hgraph import *\n",
    "from hgraph.inc_graph import *\n",
    "from hgraph.encoder import *\n",
    "import matplotlib.pyplot as plt\n",
    "from hgraph.predict import HierPredict\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86cb04b8-0a8a-4c40-8dee-c5aa1a570dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC',\n",
       " 'CC(C)C',\n",
       " 'CC(C)O',\n",
       " 'CCC(=O)O',\n",
       " 'CCC(C)C',\n",
       " 'CCC(N)=O',\n",
       " 'CCC1=CC=C(O)C=C1',\n",
       " 'CCC1=CC=CC=C1',\n",
       " 'CCC1=CN=CN1',\n",
       " 'CCC1=CNC2=C1C=CC=C2',\n",
       " 'CCCC(=O)O',\n",
       " 'CCCC(N)=O',\n",
       " 'CCCCCN',\n",
       " 'CCCCNC(=N)N',\n",
       " 'CCCSC',\n",
       " 'CCO',\n",
       " 'CCSCC(=O)CSCC',\n",
       " 'CN1CCCC1C(=O)O',\n",
       " 'CN1CCCC1C=O',\n",
       " 'CNCC(=O)O',\n",
       " 'CNCC=O',\n",
       " 'NCC=O',\n",
       " 'O=CC1CCCN1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = '/home/marcase/hgraph2graph/data/cyclic_peptides/cyclic_vocab_new.txt'\n",
    "vocab = [x.strip(\"\\r\\n \").split() for x in open(vocab)]\n",
    "vocab = PairVocab(vocab)\n",
    "vocab.vocab[21][0]\n",
    "vocab.hvocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fe21e64-1f35-47bb-80bc-167af8340104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcase/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    train = '/home/marcase/hgraph2graph/predict/preprocessed_train/'\n",
    "    train_labels = '/home/marcase/hgraph2graph/predict/preprocessed_train_labels/'\n",
    "    test = '/home/marcase/hgraph2graph/predict/preprocessed_test/'\n",
    "    test_labels = '/home/marcase/hgraph2graph/predict/preprocessed_test_labels/'\n",
    "    vocab = vocab\n",
    "    save_dir = 'test/'\n",
    "    atom_vocab = common_atom_vocab\n",
    "    load_model = None\n",
    "    seed = 7\n",
    "    rnn_type = 'LSTM'\n",
    "    hidden_size=125\n",
    "    embed_size=250\n",
    "    batch_size=32\n",
    "    latent_size=32\n",
    "    depthT=15\n",
    "    depthG=15\n",
    "    diterT=1\n",
    "    diterG=3\n",
    "    dropout=0.0\n",
    "    lr = 1e-3\n",
    "    clip_norm=5.0\n",
    "    step_beta=0.001\n",
    "    max_beta=1.0\n",
    "    warmup=10000\n",
    "    kl_anneal_iter=2000\n",
    "    epoch=2000\n",
    "    anneal_rate=0.9\n",
    "    anneal_iter=25000\n",
    "    print_iter=50\n",
    "    save_iter=1000000\n",
    "    model = '/home/marcase/hgraph2graph/ckpt/cyclic_new2/model.ckpt.140000'\n",
    "    load_model = True\n",
    "    nsample = 1\n",
    "    max_nodes=200\n",
    "    max_edges=400\n",
    "    max_AA = 6\n",
    "    max_sub_nodes = 50\n",
    "    label_size=2\n",
    "    lock_pretrain_weights=False\n",
    "    \n",
    "args=Args()\n",
    "\n",
    "model = HierVAE(args).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b784705a-68f1-4f65-8b25-4df40721ddea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuing from checkpoint /home/marcase/hgraph2graph/ckpt/cyclic_new2/model.ckpt.140000\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "\n",
    "for param in model.parameters():\n",
    "    if param.dim() == 1:\n",
    "        nn.init.constant_(param, 0)\n",
    "    else:\n",
    "        nn.init.xavier_normal_(param)\n",
    "        \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, args.anneal_rate)\n",
    "\n",
    "if args.load_model:\n",
    "    print('continuing from checkpoint ' + args.model)\n",
    "    model_state, optimizer_state, total_step, beta = torch.load(args.model)\n",
    "                \n",
    "    #initialize weights in model.predict that don't exist from pre-training\n",
    "    for key in model.predict.state_dict().keys():\n",
    "        model_state['predict.' + key] = model.predict.state_dict()[key]\n",
    "    \n",
    "    if args.lock_pretrain_weights:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        layers=list(model_state.keys())\n",
    "        layers_split = [l.split('.') for l in layers]\n",
    "        print([l for l in layers_split if 'predict' in l])\n",
    "        model.predict.ff1.requires_grad = True\n",
    "        model.predict.ff2.requires_grad = True\n",
    "\n",
    "    \n",
    "    model.load_state_dict(model_state)\n",
    "\n",
    "else:\n",
    "    total_step = beta = 0\n",
    "\n",
    "param_norm = lambda m: math.sqrt(sum([p.norm().item() ** 2 for p in m.parameters()]))\n",
    "grad_norm = lambda m: math.sqrt(sum([p.grad.norm().item() ** 2 for p in m.parameters() if p.grad is not None]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5c29424-bec0-4bd6-9e87-b5304070547b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1540686/1332252090.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1540686/1332252090.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/debugpy/_vendored/pydevd/pydevd.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads_suspended_single_notification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_thread_suspended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2062\u001b[0;31m                 \u001b[0mkeep_suspended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0mframes_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/debugpy/_vendored/pydevd/pydevd.py\u001b[0m in \u001b[0;36m_do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_internal_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2098\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_async_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_current_thread_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8bc738f-d696-4b8e-85ca-fb9b19eef079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50] Beta: 0.065, loss: 0.581, accuracy: 0.656, PNorm: 286.91, GNorm: 0.47\n",
      "Accuracy on validation set: 0.569\n",
      "[100] Beta: 0.065, loss: 0.608, accuracy: 0.719, PNorm: 287.00, GNorm: 0.49\n",
      "[150] Beta: 0.065, loss: 0.602, accuracy: 0.625, PNorm: 287.12, GNorm: 0.57\n",
      "Accuracy on validation set: 0.545\n",
      "[200] Beta: 0.065, loss: 0.540, accuracy: 0.719, PNorm: 287.24, GNorm: 0.64\n",
      "[250] Beta: 0.065, loss: 0.661, accuracy: 0.594, PNorm: 287.37, GNorm: 0.67\n",
      "Accuracy on validation set: 0.533\n",
      "[300] Beta: 0.065, loss: 0.571, accuracy: 0.594, PNorm: 287.53, GNorm: 0.62\n",
      "Accuracy on validation set: 0.541\n",
      "[350] Beta: 0.065, loss: 0.544, accuracy: 0.688, PNorm: 287.67, GNorm: 0.71\n",
      "[400] Beta: 0.065, loss: 0.529, accuracy: 0.844, PNorm: 287.84, GNorm: 0.63\n",
      "Accuracy on validation set: 0.542\n",
      "[450] Beta: 0.065, loss: 0.646, accuracy: 0.688, PNorm: 288.00, GNorm: 1.24\n",
      "[500] Beta: 0.065, loss: 0.643, accuracy: 0.625, PNorm: 288.20, GNorm: 0.91\n",
      "Accuracy on validation set: 0.543\n",
      "[550] Beta: 0.065, loss: 0.590, accuracy: 0.688, PNorm: 288.35, GNorm: 0.83\n",
      "Accuracy on validation set: 0.524\n",
      "[600] Beta: 0.065, loss: 0.537, accuracy: 0.688, PNorm: 288.51, GNorm: 0.88\n",
      "[650] Beta: 0.065, loss: 0.445, accuracy: 0.812, PNorm: 288.64, GNorm: 0.99\n",
      "Accuracy on validation set: 0.525\n",
      "[700] Beta: 0.065, loss: 0.489, accuracy: 0.781, PNorm: 288.80, GNorm: 0.93\n",
      "[750] Beta: 0.065, loss: 0.462, accuracy: 0.844, PNorm: 288.93, GNorm: 0.73\n",
      "Accuracy on validation set: 0.514\n",
      "[800] Beta: 0.065, loss: 0.463, accuracy: 0.812, PNorm: 289.11, GNorm: 1.19\n",
      "[850] Beta: 0.065, loss: 0.571, accuracy: 0.690, PNorm: 289.24, GNorm: 0.79\n",
      "Accuracy on validation set: 0.516\n",
      "[900] Beta: 0.065, loss: 0.397, accuracy: 0.812, PNorm: 289.44, GNorm: 0.97\n",
      "Accuracy on validation set: 0.511\n",
      "[950] Beta: 0.065, loss: 0.688, accuracy: 0.656, PNorm: 289.55, GNorm: 1.37\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1540686/43325597.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# loss = Variable(loss, requires_grad = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "meters = np.zeros(2)\n",
    "meters_list = list(meters)\n",
    "validation_list = list(np.zeros(1))\n",
    "total_step = 0\n",
    "for epoch in range(args.epoch):\n",
    "    random.seed(args.seed)\n",
    "    dataset_x = DataFolder(args.train, args.batch_size,shuffle = False)\n",
    "    dataset_y = DataFolder(args.train_labels, args.batch_size,shuffle = False)\n",
    "    dataset_x.data_files = ['tensors-0.pkl','tensors-1.pkl', 'tensors-2.pkl', 'tensors-3.pkl', 'tensors-4.pkl', 'tensors-5.pkl', 'tensors-6.pkl', 'tensors-7.pkl']\n",
    "    dataset_y.data_files = ['tensors_labels-0.pkl','tensors_labels-1.pkl', 'tensors_labels-2.pkl', 'tensors_labels-3.pkl', 'tensors_labels-4.pkl', 'tensors_labels-5.pkl', 'tensors_labels-6.pkl', 'tensors_labels-7.pkl']\n",
    "    model.train()\n",
    "    for batch_x,batch_y in zip(dataset_x,dataset_y):\n",
    "        total_step += 1\n",
    "        model.zero_grad()\n",
    "        y_pred = model(*batch_x, beta=beta) \n",
    "        y_true = torch.Tensor([int(y) for y in batch_y]).cuda()\n",
    "        y_true = y_true.type(torch.LongTensor).cuda()\n",
    "        loss = criterion(y_pred,y_true)\n",
    "        accuracy = torch.sum(torch.argmax(y_pred, dim=1).cuda() == y_true)/len(y_true)\n",
    "        # loss = Variable(loss, requires_grad = True)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), args.clip_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        meters = np.array([loss.item(),accuracy.cpu()])\n",
    "        meters_list.append(meters)\n",
    "\n",
    "        if total_step % args.print_iter == 0:\n",
    "            print(\"[%d] Beta: %.3f, loss: %.3f, accuracy: %.3f, PNorm: %.2f, GNorm: %.2f\" % (total_step, beta, meters[0], meters[1], param_norm(model), grad_norm(model)))\n",
    "            sys.stdout.flush()\n",
    "            meters *= 0\n",
    "        \n",
    "        if total_step % args.save_iter == 0:\n",
    "            ckpt = (model.state_dict(), optimizer.state_dict(), total_step, beta)\n",
    "            torch.save(ckpt, os.path.join(args.save_dir, f\"model.ckpt.{total_step}\"))\n",
    "\n",
    "        if total_step % args.anneal_iter == 0:\n",
    "            scheduler.step()\n",
    "            print(\"learning rate: %.6f\" % scheduler.get_lr()[0])\n",
    "\n",
    "        if total_step >= args.warmup and total_step % args.kl_anneal_iter == 0:\n",
    "            beta = min(args.max_beta, beta + args.step_beta)\n",
    "    \n",
    "    #\"validation\" set\n",
    "    model.eval()\n",
    "    dataset_x = DataFolder(args.test, args.batch_size,shuffle = False)\n",
    "    dataset_y = DataFolder(args.test_labels, args.batch_size,shuffle = False)\n",
    "    dataset_x.data_files = ['tensors-0.pkl','tensors-1.pkl', 'tensors-2.pkl']\n",
    "    dataset_y.data_files = ['tensors_labels-0.pkl','tensors_labels-1.pkl', 'tensors_labels-2.pkl']\n",
    "    random.seed()\n",
    "    i=0\n",
    "    accuracy_list = list()\n",
    "    for batch_x,batch_y in zip(dataset_x,dataset_y):\n",
    "        batch_x0 = batch_x\n",
    "        batch_y0 = batch_y\n",
    "        y_pred = model(*batch_x0, beta=beta)\n",
    "        y_pred = torch.argmax(y_pred, dim=1)\n",
    "        y_true = torch.Tensor([int(y) for y in batch_y0]).cuda()\n",
    "        y_true = y_true.type(torch.LongTensor).cuda()\n",
    "        accuracy_list.append((torch.sum(y_pred == y_true)/len(y_pred)).item())\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    print('Accuracy on validation set: %.3f' % np.average(accuracy_list))\n",
    "    validation_list.append((torch.sum(y_pred == y_true)/len(y_pred)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc7e5830-60e0-4af4-841d-f4956f9f1cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8000 [00:00<?, ?it/s]\n",
      "  0%|          | 1/8000 [00:00<50:30,  2.64it/s]\n",
      "  0%|          | 2/8000 [00:00<25:18,  5.27it/s]\u001b[A\n",
      "  0%|          | 2/8000 [00:00<26:31,  5.02it/s]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "dataset_x = DataFolder(args.train, args.batch_size,shuffle = False)\n",
    "dataset_y = DataFolder(args.train_labels, args.batch_size,shuffle = False)\n",
    "dataset_x.data_files = ['tensors-0.pkl','tensors-1.pkl', 'tensors-2.pkl', 'tensors-3.pkl', 'tensors-4.pkl', 'tensors-5.pkl', 'tensors-6.pkl', 'tensors-7.pkl']\n",
    "dataset_y.data_files = ['tensors_labels-0.pkl','tensors_labels-1.pkl', 'tensors_labels-2.pkl', 'tensors_labels-3.pkl', 'tensors_labels-4.pkl', 'tensors_labels-5.pkl', 'tensors_labels-6.pkl', 'tensors_labels-7.pkl']\n",
    "for batch_x,batch_y in zip(tqdm(dataset_x),tqdm(dataset_y)):\n",
    "    batch_x0 = batch_x\n",
    "    batch_y0 = batch_y\n",
    "    # print(len(batch_x0[1][0][5]))\n",
    "    # print(len(batch_y))\n",
    "    if i > 1:\n",
    "        break\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "accf5468-7592-4d90-9df3-bf1468e55cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True, False, False, False, False, False,  True,  True,\n",
       "        False,  True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(*batch_x, beta=beta) \n",
    "y_pred\n",
    "y_true = torch.Tensor([int(y) for y in batch_y]).cuda()\n",
    "y_true = y_true.type(torch.LongTensor).cuda()\n",
    "y_true\n",
    "torch.argmax(y_pred, dim=1).cuda() == y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee810741-5edc-4ccb-91ff-bc4c180f2f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = torch.Tensor([int(y) for y in batch_y0]).cuda()\n",
    "y_true = y_true.type(torch.LongTensor).cuda()\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c2e7027-cadc-4378-9a4d-870dba7d1ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000, device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(y_pred == y_true)/args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68b6294e-6475-48fa-b54e-096c8c937174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:00<?, ?it/s]\n",
      "  0%|          | 1/3000 [00:00<16:45,  2.98it/s]\n",
      "  0%|          | 3/3000 [00:00<05:37,  8.88it/s]\u001b[A\n",
      "  0%|          | 3/3000 [00:00<06:00,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "dataset_x = DataFolder(args.test, args.batch_size,shuffle = False)\n",
    "dataset_y = DataFolder(args.test_labels, args.batch_size,shuffle = False)\n",
    "dataset_x.data_files = ['tensors-0.pkl','tensors-1.pkl', 'tensors-2.pkl']\n",
    "dataset_y.data_files = ['tensors_labels-0.pkl','tensors_labels-1.pkl', 'tensors_labels-2.pkl']\n",
    "for batch_x,batch_y in zip(tqdm(dataset_x),tqdm(dataset_y)):\n",
    "    if i == random.randint(0, 32):\n",
    "        batch_x0 = batch_x\n",
    "        batch_y0 = batch_y\n",
    "        print(i)\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cc56f2f-4f27-4848-bb13-5d7e3acfaa61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 1, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.forward_predict(*batch_x0, beta=beta)\n",
    "y_pred = torch.argmax(y_pred, dim=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57fa7ae6-043b-4a7c-bc1b-ae12e2a9a3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "        0, 1, 1, 1, 0, 1, 1, 0], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = torch.Tensor([int(y) for y in batch_y0]).cuda()\n",
    "y_true = y_true.type(torch.LongTensor).cuda()\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c759b6a7-fc38-4f4e-8881-29ae85057b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.sum(y_pred == y_true)/args.batch_size).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b358c734-a048-4962-98b8-b60ee98f3dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5077148925537232"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6950de45-c659-4353-812b-28cd22ef01ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14, device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dcb31872-9897-437e-b3a1-8cb8fe6565d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5312, device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3b7dc4-b386-4257-949d-15b017ba3b97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hgraph-rdkit",
   "language": "python",
   "name": "hgraph-rdkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
