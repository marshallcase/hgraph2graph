{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bca8c96-4408-478f-a668-04f728d17637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcase/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#training test for prediction capabilities \n",
    "import math, random, sys\n",
    "sys.path.insert(0, '/home/marcase/hgraph2graph/')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import networkx as nx\n",
    "import rdkit\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "from hgraph import *\n",
    "from hgraph.inc_graph import *\n",
    "from hgraph.encoder import *\n",
    "import matplotlib.pyplot as plt\n",
    "from hgraph.predict import HierPredict\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86cb04b8-0a8a-4c40-8dee-c5aa1a570dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC',\n",
       " 'CC(C)C',\n",
       " 'CC(C)O',\n",
       " 'CCC(=O)O',\n",
       " 'CCC(C)C',\n",
       " 'CCC(N)=O',\n",
       " 'CCC1=CC=C(O)C=C1',\n",
       " 'CCC1=CC=CC=C1',\n",
       " 'CCC1=CN=CN1',\n",
       " 'CCC1=CNC2=C1C=CC=C2',\n",
       " 'CCCC(=O)O',\n",
       " 'CCCC(N)=O',\n",
       " 'CCCCCN',\n",
       " 'CCCCNC(=N)N',\n",
       " 'CCCSC',\n",
       " 'CCO',\n",
       " 'CCSCC(=O)CSCC',\n",
       " 'CN1CCCC1C(=O)O',\n",
       " 'CN1CCCC1C=O',\n",
       " 'CNCC(=O)O',\n",
       " 'CNCC=O',\n",
       " 'NCC=O',\n",
       " 'O=CC1CCCN1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = '/home/marcase/hgraph2graph/data/cyclic_peptides/cyclic_vocab_new.txt'\n",
    "vocab = [x.strip(\"\\r\\n \").split() for x in open(vocab)]\n",
    "vocab = PairVocab(vocab)\n",
    "vocab.vocab[21][0]\n",
    "vocab.hvocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fe21e64-1f35-47bb-80bc-167af8340104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcase/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    train = '/home/marcase/hgraph2graph/predict/preprocessed_train/'\n",
    "    train_labels = '/home/marcase/hgraph2graph/predict/preprocessed_train_labels/'\n",
    "    test = '/home/marcase/hgraph2graph/predict/preprocessed_test/'\n",
    "    test_labels = '/home/marcase/hgraph2graph/predict/preprocessed_test_labels/'\n",
    "    vocab = vocab\n",
    "    save_dir = 'test/'\n",
    "    atom_vocab = common_atom_vocab\n",
    "    load_model = None\n",
    "    seed = 7\n",
    "    rnn_type = 'LSTM'\n",
    "    hidden_size=125\n",
    "    embed_size=250\n",
    "    batch_size=32\n",
    "    latent_size=32\n",
    "    depthT=15\n",
    "    depthG=15\n",
    "    diterT=1\n",
    "    diterG=3\n",
    "    dropout=0.0\n",
    "    lr = 1e-3\n",
    "    clip_norm=5.0\n",
    "    step_beta=0.001\n",
    "    max_beta=1.0\n",
    "    warmup=10000\n",
    "    kl_anneal_iter=2000\n",
    "    epoch=2000\n",
    "    anneal_rate=0.9\n",
    "    anneal_iter=25000\n",
    "    print_iter=50\n",
    "    save_iter=1000000\n",
    "    model = '/home/marcase/hgraph2graph/ckpt/cyclic_new2/model.ckpt.140000'\n",
    "    load_model = True\n",
    "    nsample = 1\n",
    "    max_nodes=200\n",
    "    max_edges=400\n",
    "    max_AA = 6\n",
    "    max_sub_nodes = 50\n",
    "    label_size=2\n",
    "    lock_pretrain_weights=False\n",
    "    \n",
    "args=Args()\n",
    "\n",
    "model = HierVAE(args).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b784705a-68f1-4f65-8b25-4df40721ddea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuing from checkpoint /home/marcase/hgraph2graph/ckpt/cyclic_new2/model.ckpt.140000\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "\n",
    "for param in model.parameters():\n",
    "    if param.dim() == 1:\n",
    "        nn.init.constant_(param, 0)\n",
    "    else:\n",
    "        nn.init.xavier_normal_(param)\n",
    "        \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, args.anneal_rate)\n",
    "\n",
    "if args.load_model:\n",
    "    print('continuing from checkpoint ' + args.model)\n",
    "    model_state, optimizer_state, total_step, beta = torch.load(args.model)\n",
    "                \n",
    "    #initialize weights in model.predict that don't exist from pre-training\n",
    "    for key in model.predict.state_dict().keys():\n",
    "        model_state['predict.' + key] = model.predict.state_dict()[key]\n",
    "    \n",
    "    if args.lock_pretrain_weights:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        layers=list(model_state.keys())\n",
    "        layers_split = [l.split('.') for l in layers]\n",
    "        print([l for l in layers_split if 'predict' in l])\n",
    "        model.predict.ff1.requires_grad = True\n",
    "        model.predict.ff2.requires_grad = True\n",
    "\n",
    "    \n",
    "    model.load_state_dict(model_state)\n",
    "\n",
    "else:\n",
    "    total_step = beta = 0\n",
    "\n",
    "param_norm = lambda m: math.sqrt(sum([p.norm().item() ** 2 for p in m.parameters()]))\n",
    "grad_norm = lambda m: math.sqrt(sum([p.grad.norm().item() ** 2 for p in m.parameters() if p.grad is not None]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c4b1e0-ba2c-473c-b2af-5d6ad9f71773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8bc738f-d696-4b8e-85ca-fb9b19eef079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50] Beta: 0.065, loss: 1.012, accuracy: 0.421, PNorm: 286.57, GNorm: 0.00\n",
      "27\n",
      "Accuracy on validation set: 0.469\n",
      "[100] Beta: 0.065, loss: 0.996, accuracy: 0.432, PNorm: 286.57, GNorm: 0.00\n",
      "[150] Beta: 0.065, loss: 1.017, accuracy: 0.409, PNorm: 286.57, GNorm: 0.00\n",
      "Accuracy on validation set: 0.531\n",
      "[200] Beta: 0.065, loss: 0.993, accuracy: 0.425, PNorm: 286.57, GNorm: 0.00\n",
      "[250] Beta: 0.065, loss: 1.014, accuracy: 0.424, PNorm: 286.57, GNorm: 0.00\n",
      "18\n",
      "Accuracy on validation set: 0.531\n",
      "[300] Beta: 0.065, loss: 1.011, accuracy: 0.419, PNorm: 286.57, GNorm: 0.00\n",
      "4\n",
      "Accuracy on validation set: 0.469\n",
      "[350] Beta: 0.065, loss: 0.993, accuracy: 0.436, PNorm: 286.57, GNorm: 0.00\n",
      "[400] Beta: 0.065, loss: 1.033, accuracy: 0.436, PNorm: 286.57, GNorm: 0.00\n",
      "16\n",
      "Accuracy on validation set: 0.344\n",
      "[450] Beta: 0.065, loss: 0.993, accuracy: 0.428, PNorm: 286.57, GNorm: 0.00\n",
      "[500] Beta: 0.065, loss: 1.016, accuracy: 0.412, PNorm: 286.57, GNorm: 0.00\n",
      "Accuracy on validation set: 0.312\n",
      "[550] Beta: 0.065, loss: 1.021, accuracy: 0.429, PNorm: 286.57, GNorm: 0.00\n",
      "Accuracy on validation set: 0.312\n",
      "[600] Beta: 0.065, loss: 1.003, accuracy: 0.421, PNorm: 286.57, GNorm: 0.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1300706/87582494.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtotal_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hgraph2graph/hgraph/hgnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, tensors, orders, beta, perturb_z)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperturb_z\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mtree_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mroot_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mroot_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_kl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperturb_z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_vecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hgraph2graph/hgraph/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tree_tensors, graph_tensors)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhinter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mhnode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhmess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mhroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mst\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hgraph2graph/hgraph/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, fnode, fmess, agraph, bgraph)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_hidden_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mnei_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_select_ND\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hgraph2graph/hgraph/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, fmess, bgraph)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mh_nei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_select_ND\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mc_nei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_select_ND\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_nei\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_nei\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hgraph2graph/hgraph/rnn.py\u001b[0m in \u001b[0;36mLSTM\u001b[0;34m(self, x, h_nei, c_nei)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_f\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_expand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_nei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_sum_nei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc_nei\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "meters = np.zeros(2)\n",
    "meters_list = list(meters)\n",
    "validation_list = list(np.zeros(1))\n",
    "total_step = 0\n",
    "for epoch in range(args.epoch):\n",
    "    random.seed(args.seed)\n",
    "    dataset_x = DataFolder(args.train, args.batch_size,shuffle = False)\n",
    "    dataset_y = DataFolder(args.train_labels, args.batch_size,shuffle = False)\n",
    "    dataset_x.data_files = ['tensors-0.pkl','tensors-1.pkl', 'tensors-2.pkl', 'tensors-3.pkl', 'tensors-4.pkl', 'tensors-5.pkl', 'tensors-6.pkl', 'tensors-7.pkl']\n",
    "    dataset_y.data_files = ['tensors_labels-0.pkl','tensors_labels-1.pkl', 'tensors_labels-2.pkl', 'tensors_labels-3.pkl', 'tensors_labels-4.pkl', 'tensors_labels-5.pkl', 'tensors_labels-6.pkl', 'tensors_labels-7.pkl']\n",
    "    model.train()\n",
    "    for batch_x,batch_y in zip(dataset_x,dataset_y):\n",
    "        total_step += 1\n",
    "        model.zero_grad()\n",
    "        y_pred = model.forward(*batch_x, beta=beta) \n",
    "        y_true = torch.Tensor([int(y) for y in batch_y]).cuda()\n",
    "        y_true = y_true.type(torch.LongTensor).cuda()\n",
    "        loss = criterion(y_pred,y_true)\n",
    "        \n",
    "        accuracy = torch.sum(torch.argmax(y_pred, dim=1).cuda() == y_true)/len(y_pred)\n",
    "        loss = Variable(loss, requires_grad = True)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), args.clip_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        meters = meters + np.array([loss.item(),accuracy.cpu()])\n",
    "        meters_list.append(meters)\n",
    "\n",
    "        if total_step % args.print_iter == 0:\n",
    "            meters /= args.print_iter\n",
    "            print(\"[%d] Beta: %.3f, loss: %.3f, accuracy: %.3f, PNorm: %.2f, GNorm: %.2f\" % (total_step, beta, meters[0], meters[1], param_norm(model), grad_norm(model)))\n",
    "            sys.stdout.flush()\n",
    "            meters *= 0\n",
    "        \n",
    "        if total_step % args.save_iter == 0:\n",
    "            ckpt = (model.state_dict(), optimizer.state_dict(), total_step, beta)\n",
    "            torch.save(ckpt, os.path.join(args.save_dir, f\"model.ckpt.{total_step}\"))\n",
    "\n",
    "        if total_step % args.anneal_iter == 0:\n",
    "            scheduler.step()\n",
    "            print(\"learning rate: %.6f\" % scheduler.get_lr()[0])\n",
    "\n",
    "        if total_step >= args.warmup and total_step % args.kl_anneal_iter == 0:\n",
    "            beta = min(args.max_beta, beta + args.step_beta)\n",
    "    \n",
    "    #\"validation\" set\n",
    "    model.eval()\n",
    "    torch.no_grad()\n",
    "    dataset_x = DataFolder(args.test, args.batch_size,shuffle = False)\n",
    "    dataset_y = DataFolder(args.test_labels, args.batch_size,shuffle = False)\n",
    "    dataset_x.data_files = ['tensors-0.pkl','tensors-1.pkl', 'tensors-2.pkl']\n",
    "    dataset_y.data_files = ['tensors_labels-0.pkl','tensors_labels-1.pkl', 'tensors_labels-2.pkl']\n",
    "    random.seed()\n",
    "    i=0\n",
    "    for batch_x,batch_y in zip(dataset_x,dataset_y):\n",
    "        if i == random.randint(0, 32):\n",
    "            batch_x0 = batch_x\n",
    "            batch_y0 = batch_y\n",
    "            print(i)\n",
    "            break\n",
    "        i += 1\n",
    "\n",
    "    y_pred = model.forward(*batch_x0, beta=beta)\n",
    "    y_pred = torch.argmax(y_pred, dim=1)\n",
    "    y_true = torch.Tensor([int(y) for y in batch_y0]).cuda()\n",
    "    y_true = y_true.type(torch.LongTensor).cuda()\n",
    "    print('Accuracy on validation set: %.3f' % (torch.sum(y_pred == y_true)/len(y_pred)).item())\n",
    "    validation_list.append((torch.sum(y_pred == y_true)/len(y_pred)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc7e5830-60e0-4af4-841d-f4956f9f1cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8000 [00:00<?, ?it/s]\n",
      "  0%|          | 1/8000 [00:00<50:30,  2.64it/s]\n",
      "  0%|          | 2/8000 [00:00<25:18,  5.27it/s]\u001b[A\n",
      "  0%|          | 2/8000 [00:00<26:31,  5.02it/s]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "dataset_x = DataFolder(args.train, args.batch_size,shuffle = False)\n",
    "dataset_y = DataFolder(args.train_labels, args.batch_size,shuffle = False)\n",
    "dataset_x.data_files = ['tensors-0.pkl','tensors-1.pkl', 'tensors-2.pkl', 'tensors-3.pkl', 'tensors-4.pkl', 'tensors-5.pkl', 'tensors-6.pkl', 'tensors-7.pkl']\n",
    "dataset_y.data_files = ['tensors_labels-0.pkl','tensors_labels-1.pkl', 'tensors_labels-2.pkl', 'tensors_labels-3.pkl', 'tensors_labels-4.pkl', 'tensors_labels-5.pkl', 'tensors_labels-6.pkl', 'tensors_labels-7.pkl']\n",
    "for batch_x,batch_y in zip(tqdm(dataset_x),tqdm(dataset_y)):\n",
    "    batch_x0 = batch_x\n",
    "    batch_y0 = batch_y\n",
    "    # print(len(batch_x0[1][0][5]))\n",
    "    # print(len(batch_y))\n",
    "    if i > 1:\n",
    "        break\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accf5468-7592-4d90-9df3-bf1468e55cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        1, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.forward_predict(*batch_x0, beta=beta)\n",
    "y_pred = torch.argmax(y_pred, dim=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee810741-5edc-4ccb-91ff-bc4c180f2f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = torch.Tensor([int(y) for y in batch_y0]).cuda()\n",
    "y_true = y_true.type(torch.LongTensor).cuda()\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c2e7027-cadc-4378-9a4d-870dba7d1ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000, device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(y_pred == y_true)/args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68b6294e-6475-48fa-b54e-096c8c937174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:00<?, ?it/s]\n",
      "  0%|          | 1/3000 [00:00<16:45,  2.98it/s]\n",
      "  0%|          | 3/3000 [00:00<05:37,  8.88it/s]\u001b[A\n",
      "  0%|          | 3/3000 [00:00<06:00,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "dataset_x = DataFolder(args.test, args.batch_size,shuffle = False)\n",
    "dataset_y = DataFolder(args.test_labels, args.batch_size,shuffle = False)\n",
    "dataset_x.data_files = ['tensors-0.pkl','tensors-1.pkl', 'tensors-2.pkl']\n",
    "dataset_y.data_files = ['tensors_labels-0.pkl','tensors_labels-1.pkl', 'tensors_labels-2.pkl']\n",
    "for batch_x,batch_y in zip(tqdm(dataset_x),tqdm(dataset_y)):\n",
    "    if i == random.randint(0, 32):\n",
    "        batch_x0 = batch_x\n",
    "        batch_y0 = batch_y\n",
    "        print(i)\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cc56f2f-4f27-4848-bb13-5d7e3acfaa61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 1, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.forward_predict(*batch_x0, beta=beta)\n",
    "y_pred = torch.argmax(y_pred, dim=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57fa7ae6-043b-4a7c-bc1b-ae12e2a9a3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "        0, 1, 1, 1, 0, 1, 1, 0], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = torch.Tensor([int(y) for y in batch_y0]).cuda()\n",
    "y_true = y_true.type(torch.LongTensor).cuda()\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c759b6a7-fc38-4f4e-8881-29ae85057b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.sum(y_pred == y_true)/args.batch_size).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b358c734-a048-4962-98b8-b60ee98f3dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hgraph.dataset.DataFolder at 0x14e446207790>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6950de45-c659-4353-812b-28cd22ef01ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hgraph-rdkit",
   "language": "python",
   "name": "hgraph-rdkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
