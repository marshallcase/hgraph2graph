{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63d3b480-7815-46ef-b03c-08224b3b9fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcase/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#generation debugging \n",
    "import sys\n",
    "sys.path.insert(0, '/home/marcase/hgraph2graph/')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import networkx as nx\n",
    "import rdkit\n",
    "import math, random\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "from hgraph import *\n",
    "from hgraph.inc_graph import *\n",
    "from hgraph.encoder import *\n",
    "from hgraph.decoder import *\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import DataStructs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0455dac4-291a-45fc-866a-f7fb2ced103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = '/home/marcase/hgraph2graph/vocab23oct22.txt'\n",
    "vocab = '/scratch/gthurber_root/gthurber0/marcase/preprocess_mono/preprocess_generated_real/vocab26oct22.txt'\n",
    "vocab = [x.strip(\"\\r\\n \").split() for x in open(vocab)]\n",
    "vocab = PairVocab(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f9a9fa1-eaf1-464f-9154-c30e01016f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcase/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    train = '/scratch/gthurber_root/gthurber0/marcase/preprocess_mono/preprocess_generated_real/train/'\n",
    "    vocab = vocab\n",
    "    save_dir = 'test/'\n",
    "    atom_vocab = common_atom_vocab\n",
    "    load_model = None\n",
    "    seed = 7\n",
    "    rnn_type = 'LSTM'\n",
    "    hidden_size=250\n",
    "    embed_size=250\n",
    "    batch_size=10\n",
    "    latent_size=32\n",
    "    depthT=15\n",
    "    depthG=15\n",
    "    diterT=1\n",
    "    diterG=3\n",
    "    dropout=0.0\n",
    "    lr = 1e-3\n",
    "    clip_norm=5.0\n",
    "    step_beta=0.001\n",
    "    max_beta=1.0\n",
    "    warmup=10000\n",
    "    kl_anneal_iter=2000\n",
    "    epoch=20\n",
    "    anneal_rate=0.9\n",
    "    anneal_iter=25000\n",
    "    print_iter=50\n",
    "    save_iter=5000\n",
    "    model = '/scratch/gthurber_root/gthurber0/marcase/preprocess_mono/preprocess_generated_real/ckpt/pretrained/model.ckpt.340000'\n",
    "    load_model = True\n",
    "    nsample = 20\n",
    "    max_nodes=250\n",
    "    max_edges=500\n",
    "    max_AA = 15\n",
    "    max_sub_nodes = 100\n",
    "    label_size=2\n",
    "    \n",
    "args=Args()\n",
    "\n",
    "model = HierVAE(args).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d9a34d9-479b-4303-bbaa-ae9c705687fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #Params: 17779K\n"
     ]
    }
   ],
   "source": [
    "print(\"Model #Params: %dK\" % (sum([x.nelement() for x in model.parameters()]) / 1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b4e45d0-a264-4137-afd6-3fc1f1464d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from generate\n",
    "model.load_state_dict(torch.load(args.model)[0])\n",
    "model.eval()\n",
    "# torch.manual_seed(args.seed)\n",
    "torch.manual_seed(np.random.randint(1,1000))\n",
    "# random.seed(args.seed)\n",
    "random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f3addf8-f170-40bb-9487-8f5d30b9d063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 2)\n",
      "(2500, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CSCCC1SC(Cc2ccc(O)cc2)C2NC(=O)C(Cc3ccc(O)cc3)NC(=O)C(CC(N)=O)NC(=O)C(CO)(NC(=O)CNC(=O)CNC(=O)C(CO)(NC(=O)C(N)CCC(N)=O)C(Cc3c[nH]c4ccccc34)SCC1=O)C(C)SC(CC(C)C)C(=O)C(CCCNC(=N)N)SCC(C(=O)N1CCCC1C(=O)O)NC(=O)CNC(=O)CNC2=O', 'CC1NC(=O)CNC(=O)C2CCCN2C(=O)C(NC(=O)C(N)CCC(N)=O)CSCC(=O)CSCC2NC(=O)C(Cc3c[nH]c4ccccc34)NC(=O)C(CSCC(=O)CSCC(C(=O)NC(CC(N)=O)C(=O)O)NC2=O)NC1=O', 'CC(O)C(N)C(=O)NC1CSCC(=O)CSCC(C(=O)NCC(=O)O)NC(=O)C(Cc2ccccc2)NC(=O)CNC(=O)C2CSCC(=O)CSCC(NC(=O)C(CCCNC(=N)N)NC(=O)CNC1=O)C(=O)NCC(=O)N2', 'NCCCCC1NC(=O)CNC(=O)C2CSCC(=O)CSCC(NC(=O)C(N)CCC(=O)O)C(=O)NCC(=O)NCC(=O)NC(CSCC(=O)CSCC(C(=O)NCC(=O)O)NC1=O)C(=O)N1CCCC1C(=O)N2', 'CC(C)CNCC(=O)O', 'NCCCCC(NC(=O)C(CO)NC(=O)C(NCCC(=O)O)C(CCC(N)=O)C(=O)O)C(=O)NC(NC1CSCC(=O)CSC(NCC(=O)O)C(C=O)(Cc2c[nH]c3ccccc23)NC(=O)C(Cc2ccccc2)NC(=O)CNC1=O)C(=O)CCC(N)=O', 'CSCCC1NC(=O)CNC(=O)C2CSCC(=O)CSCC(C(=O)N3CCCC3C(=O)O)NC(=O)C(Cc3ccc(O)cc3)NC(=O)CNC(=O)C(CSCC(=O)CSCC(NC(=O)C(N)CO)C(=O)NCC(=O)N2)NC(=O)C(Cc2cnc[nH]2)NC(=O)CNC1=O', 'CC(O)C(N)C(=O)NC1CSCC(=O)CSCC(C(=O)NC2CSCC(=O)CSCC(C(=O)NC(Cc3ccccc3)C(=O)O)NC(=O)C(CO)NC(=O)CNC(=O)CNC(=O)CNC2=O)NC(=O)C(Cc2cnc[nH]2)NC(=O)CNC(=O)CNC(=O)CNC1=O', 'CCC(C)C1SC(CCSC)C(CCC(=O)O)(C(=O)N2CCCC2C(=O)O)NC(=O)CNC(=O)CNC(=O)C2(Cc3ccccc3)NC(=O)CNC(=O)CNC(=O)C(NC(=O)CNC(=O)C(CCCNC(=N)N)(NC(=O)C(N)CC(N)=O)C(Cc3ccccc3)SCC1=O)C(CCC(=O)O)SC(C(C)C)C(=O)C(Cc1c[nH]c3ccccc13)SC2CO', 'CC(O)CNCC(=O)O']\n",
      "(2500, 2)\n",
      "(2500, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CC(C)CC(NC(=O)C1CSCC(=O)CSCC2NC(=O)CNC(=O)CNC(=O)C(NC(=O)C(N)CO)CSCC(=O)CSCC(NC(=O)C(Cc3ccc(O)cc3)NC2=O)C(=O)NCC(=O)NC(CCCNC(=N)N)C(=O)N1)C(=O)O', 'CSCCC(N)C(=O)NC1CSCC(=O)CSCC(C(=O)NC(Cc2ccccc2)C(=O)O)NC(=O)C2CSCC(=O)CSCC(NC(=O)C(CO)NC(=O)CNC(=O)C3CCCN3C1=O)C(=O)NC(C(C)C)C(=O)NC(Cc1ccc(O)cc1)C(=O)NC(C)C(=O)N2', 'NC(CO)C(=O)NC1CSCC(=O)CSCC(C(=O)NC(CO)C(=O)O)NC(=O)C(CCC(=O)O)NC(=O)CNC(=O)C2CSCC(=O)CSCC(NC(=O)C(Cc3c[nH]c4ccccc34)NC1=O)C(=O)NCC(=O)NCC(=O)NCC(=O)N2', 'N=C(N)NCCCC1NC(=O)C(NC(=O)CN)CSCC(=O)CSCC(C(=O)N2CCCC2C(=O)O)NC(=O)C(CCC(=O)O)NC(=O)CNC(=O)C2CSCC(=O)CSCC(NC1=O)C(=O)NC(Cc1ccc(O)cc1)C(=O)NC(CO)C(=O)NCC(=O)NCC(=O)N2', 'CCC(C)CC(CNC(C)C(=O)O)(Cc1cnc[nH]1)C(=O)C(N)C(C)O', 'CCC(C)C1NC(=O)C(Cc2ccc(O)cc2)NC(=O)C(NC(=O)C(Cc2c[nH]c3ccccc23)NC(=O)C2CSCC(=O)CSCC(NC(=O)C(N)CO)C(=O)NCC(=O)NC(CCC(=O)O)C(=O)N2)CSCC(=O)CSCC(C(=O)NC(CC(N)=O)C(=O)O)NC(=O)C(CCCNC(=N)N)NC1=O', 'CCC(C)C(NC(=O)C1CSCC(=O)CSCC(NC(=O)C2CSCC(=O)CSCC(NC(=O)C(N)CC(C)C)C(=O)NCC(=O)NCC(=O)NC(Cc3c[nH]c4ccccc34)C(=O)N2)C(=O)NCC(=O)NC(Cc2ccc(O)cc2)C(=O)N1)C(=O)O', 'CCC(C)c1nc[nH]c1C(NC(NC(NC1CSCC(=O)C(CO)SC(Cc2ccc(O)cc2)C(C=O)(C(C)CC)NC(=O)CNC(=O)CNC(=O)C(NC(Cc2cnc[nH]2)C(=O)O)NC1=O)C(=O)CCC(N)=O)C(=O)Cc1ccc(O)cc1)C(=O)C(CC(=O)O)NCCc1cnc[nH]1', 'O=C(O)CNCCc1ccc(O)cc1', 'CC(C)CNC(CCCNC(=N)N)C(=O)Cc1ccc(NC(CCCCN)C(=O)NCC(=O)NC(CO)C(=O)O)cc1Cc1ccccc1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for _ in tqdm(range(args.nsample // args.batch_size)):\n",
    "        smiles_list = model.sample(args.batch_size, greedy=True,max_AA=args.max_AA)\n",
    "        print(smiles_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcb0cf99-2501-44bf-b767-a1c0b80e5665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similarity\n",
    "ms = [Chem.MolFromSmiles('CCOC'), Chem.MolFromSmiles('CCO'),Chem.MolFromSmiles('COC')]\n",
    "fps = [Chem.RDKFingerprint(x) for x in ms]\n",
    "DataStructs.FingerprintSimilarity(fps[0],fps[2],metric=DataStructs.TanimotoSimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1de008a3-eae6-453c-bba4-bf8d47ef1e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48890714872637636"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similarity - generated_molecules\n",
    "ms = [Chem.MolFromSmiles(i) for i in smiles_list]\n",
    "fps = [Chem.RDKFingerprint(x) for x in ms]\n",
    "DataStructs.FingerprintSimilarity(fps[0],fps[4],metric=DataStructs.TanimotoSimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27717d77-5f11-4548-b45f-4722ff0ed941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CCC(C)C(NC(=O)CNC(=O)C(F)NC(=O)C(N)C(C)O)C(=O)NCC(=O)NCC(=O)NC(F)C(=O)NCC(=O)NC(Cc1ccccc1)C(=O)NCC(=O)NC(CO)C(=O)O'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chem.MolToSmiles(Chem.ReplaceSubstructs(Chem.MolFromSmiles(smiles_list[1]), \n",
    "                                 Chem.MolFromSmiles('CSCC(CSC)=O'), \n",
    "                                 Chem.MolFromSmiles('F'),\n",
    "                                 replaceAll=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be0608da-2c68-47b1-9294-a446d237caef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol2seq(m):\n",
    "    aa_smiles = {'ALA': 'C[C@H](N)C=O', 'CYS': 'N[C@H](C=O)CS', 'ASP': 'N[C@H](C=O)CC(=O)O', 'GLU': 'N[C@H](C=O)CCC(=O)O', 'PHE': 'N[C@H](C=O)Cc1ccccc1', 'GLY': 'NCC=O', 'HIS': 'N[C@H](C=O)Cc1c[nH]cn1', 'ILE': 'CC[C@H](C)[C@H](N)C=O', 'LYS': 'NCCCC[C@H](N)C=O', 'LEU': 'CC(C)C[C@H](N)C=O', 'MET': 'CSCC[C@H](N)C=O', 'ASN': 'NC(=O)C[C@H](N)C=O', 'PRO': 'O=C[C@@H]1CCCN1', 'GLN': 'NC(=O)CC[C@H](N)C=O', 'ARG': 'N=C(N)NCCC[C@H](N)C=O', 'SER': 'N[C@H](C=O)CO', 'THR': 'C[C@@H](O)[C@H](N)C=O', 'VAL': 'CC(C)[C@H](N)C=O', 'TRP': 'N[C@H](C=O)Cc1c[nH]c2ccccc12','TYR': 'N[C@H](C=O)Cc1ccc(O)cc1'}\n",
    "    aas = ['GLY','ALA', 'VAL', 'CYS', 'ASP', 'GLU', 'PHE', 'HIS', 'ILE', 'LYS', 'LEU', 'MET', 'ASN', 'PRO', 'GLN', 'ARG', 'SER', 'THR', 'TRP','TYR'] #order important because gly is substructure of other aas\n",
    "    # detect the atoms of the backbone and assign them with info\n",
    "    CAatoms = m.GetSubstructMatches(Chem.MolFromSmarts(\"[C:0](=[O:1])[C:2][N:3]\"))\n",
    "    for atoms in CAatoms:\n",
    "        a = m.GetAtomWithIdx(atoms[2])\n",
    "        info = Chem.AtomPDBResidueInfo()\n",
    "        info.SetName(\" CA \") #spaces are important\n",
    "        a.SetMonomerInfo(info)\n",
    "    # detect the presence of residues and set residue name for CA atoms only\n",
    "    for curr_aa in aas:\n",
    "        matches = m.GetSubstructMatches(Chem.MolFromSmiles(aa_smiles[curr_aa]))\n",
    "        for atoms in matches:\n",
    "            for atom in atoms:\n",
    "                a = m.GetAtomWithIdx(atom)\n",
    "                info = Chem.AtomPDBResidueInfo()\n",
    "                if a.GetMonomerInfo() != None:\n",
    "                    if a.GetMonomerInfo().GetName() == \" CA \":\n",
    "                        info.SetName(\" CA \")\n",
    "                        info.SetResidueName(curr_aa)\n",
    "                        a.SetMonomerInfo(info)\n",
    "    # renumber the backbone atoms so the sequence order is correct:\n",
    "    bbsmiles = \"O\"+\"C(=O)CN\"*len(m.GetSubstructMatches(Chem.MolFromSmiles(aa_smiles[\"GLY\"]))) # generate backbone SMILES\n",
    "    backbone = m.GetSubstructMatches(Chem.MolFromSmiles(bbsmiles))[0]\n",
    "    id_list = list(backbone)\n",
    "    id_list.reverse()\n",
    "    for idx in [a.GetIdx() for a in m.GetAtoms()]:\n",
    "        if idx not in id_list:\n",
    "            id_list.append(idx)\n",
    "    m_renum = Chem.RenumberAtoms(m,newOrder=id_list)\n",
    "    return Chem.MolToSequence(m_renum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "40bfdb59-8732-496e-83b9-d93d460624b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TGGIGGAGFGS'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mol = Chem.MolFromSmiles('CCC(C(C(NCC(NCC(NC(C(NCC(NC(C(NCC(NC(C(O)=O)CO)=O)=O)Cc1ccccc1)=O)=O)C)=O)=O)=O)NC(CNC(CNC(C(C(O)C)N)=O)=O)=O)C')\n",
    "mol2seq(test_mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19b1efca-def5-46a5-a296-3b0b094d4d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #begin training the model\n",
    "# for batch in tqdm(dataset):\n",
    "#     total_step += 1\n",
    "#     model.zero_grad()\n",
    "#     loss, kl_div, wacc, iacc, tacc, sacc = model(*batch, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5749de5f-58f0-4378-bdb1-60f2c4ff90d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file0 = os.path.join(dataset.data_folder,'tensors-0.pkl')\n",
    "with open(data_file0,'rb') as f:\n",
    "    batches = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ee826d-e94f-45ea-bd95-095069659867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.9945, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 42.87664031982422,\n",
       " tensor(0.9921, device='cuda:0'),\n",
       " tensor(1., device='cuda:0'),\n",
       " tensor(1., device='cuda:0'),\n",
       " tensor(1., device='cuda:0'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(*batches[0],beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dce7bb9-2526-45fd-b4b1-349f6baf5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.draw(batches[0][0][1])\n",
    "# plt.show()\n",
    "\n",
    "#just realized I have no idea what format the tensorized molecules are in. let's go back and check the tensorize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db527a00-e43f-40e1-b078-78bd871a51bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from model.sample()\n",
    "batch_size = args.batch_size\n",
    "latent_size = args.latent_size\n",
    "root_vecs = torch.randn(batch_size, latent_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eedd6972-2e97-47b5-ac8e-694671bcc5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from HierMPNDecoder.decode()\n",
    "src_root_vecs, src_tree_vecs, src_graph_vecs = root_vecs,root_vecs,root_vecs\n",
    "batch_size = len(src_root_vecs)\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34b97185-7dbf-4225-ab34-86aea505ad62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "tree_batch = IncTree(batch_size, node_fdim=2, edge_fdim=3)\n",
    "# nx.draw(tree_batch.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c02e0261-8a50-444e-b338-cd3072969e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmpn = IncHierMPNEncoder(args.vocab, args.atom_vocab, args.rnn_type, args.embed_size, args.hidden_size, args.depthT, args.depthG, args.dropout)\n",
    "test = hmpn.tree_encoder\n",
    "test.depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36d9cad5-5b11-44ff-acc6-f34085d6b117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 38)\n"
     ]
    }
   ],
   "source": [
    "graph_batch = IncGraph(args.atom_vocab, batch_size, node_fdim=hmpn.atom_size, edge_fdim=hmpn.atom_size + hmpn.bond_size)\n",
    "# nx.draw(graph_batch.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "983cb9b1-a89e-4689-a1a3-1dd01d29e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cls_score(src_tree_vecs, batch_idx, cls_vecs, cls_labs):\n",
    "    use_attention = False\n",
    "    if use_attention:\n",
    "        cls_cxt = self.attention(src_tree_vecs, batch_idx, cls_vecs, self.A_cls)\n",
    "    else:\n",
    "        cls_cxt = src_tree_vecs.index_select(index=batch_idx, dim=0).cuda()\n",
    "\n",
    "    cls_vecs = torch.cat([cls_vecs, cls_cxt], dim=-1).cuda()\n",
    "    clsNN = nn.Sequential(\n",
    "                nn.Linear(args.hidden_size + args.latent_size, args.hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(args.dropout),\n",
    "                nn.Linear(args.hidden_size, args.vocab.size()[0])\n",
    "        ).cuda()\n",
    "    iclsNN = nn.Sequential(\n",
    "                nn.Linear(args.hidden_size + args.latent_size, args.hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(args.dropout),\n",
    "                nn.Linear(args.hidden_size, args.vocab.size()[1])\n",
    "        ).cuda()\n",
    "    cls_scores = clsNN(cls_vecs)\n",
    "\n",
    "    if cls_labs is None: #inference mode\n",
    "        icls_scores = iclsNN(cls_vecs) #no masking\n",
    "    else:\n",
    "        vocab_masks = args.vocab.get_mask(cls_labs)\n",
    "        icls_scores = iclsNN(cls_vecs) + vocab_masks #apply mask by log(x + mask): mask=0 or -INF\n",
    "    return cls_scores, icls_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00d1b1b5-c598-46df-8f67-48c0a5a9299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = [[] for i in range(batch_size)]\n",
    "W_root = nn.Linear(args.latent_size, args.hidden_size).cuda()\n",
    "init_vecs = src_root_vecs if args.latent_size == args.hidden_size else W_root(src_root_vecs)\n",
    "itensor = torch.LongTensor([]).cuda()\n",
    "batch_idx = itensor.new_tensor(range(batch_size))\n",
    "cls_scores, icls_scores = get_cls_score(src_tree_vecs, batch_idx, init_vecs, None)\n",
    "root_cls = cls_scores.max(dim=-1)[1]\n",
    "icls_scores = icls_scores + args.vocab.get_mask(root_cls)\n",
    "root_cls, root_icls = root_cls.tolist(), icls_scores.max(dim=-1)[1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d38035ac-5978-489e-82b9-33d9ce2add2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "super_root = tree_batch.add_node() \n",
    "for bid in range(batch_size):\n",
    "    clab, ilab = root_cls[bid], root_icls[bid]\n",
    "    root_idx = tree_batch.add_node( batch_idx.new_tensor([clab, ilab]) )\n",
    "    tree_batch.add_edge(super_root, root_idx) \n",
    "    stack[bid].append(root_idx)\n",
    "\n",
    "    root_smiles = args.vocab.get_ismiles(ilab)\n",
    "    new_atoms, new_bonds, attached = graph_batch.add_mol(bid, root_smiles, [], 0)\n",
    "    tree_batch.register_cgraph(root_idx, new_atoms, new_bonds, attached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1819a370-d1b5-40d7-9853-52f88a630aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.draw(tree_batch.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0c42b7c-4732-49c4-80cf-ea20df1bf641",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HTuple():\n",
    "    def __init__(self, node=None, mess=None, vmask=None, emask=None):\n",
    "        self.node, self.mess = node, mess\n",
    "        self.vmask, self.emask = vmask, emask\n",
    "#invariance: tree_tensors is equal to inter_tensors (but inter_tensor's init_vec is 0)\n",
    "tree_tensors = tree_batch.get_tensors()\n",
    "graph_tensors = graph_batch.get_tensors()\n",
    "\n",
    "htree = HTuple( mess = hmpn.tree_encoder.rnn.get_init_state(tree_tensors[1]) )\n",
    "hinter = HTuple( mess = hmpn.tree_encoder.rnn.get_init_state(tree_tensors[1]) )\n",
    "hgraph = HTuple( mess = hmpn.tree_encoder.rnn.get_init_state(graph_tensors[1]) )\n",
    "h = hmpn.tree_encoder.rnn.get_hidden_state(htree.mess)\n",
    "h[1 : batch_size + 1] = init_vecs #wiring root (only for tree, not inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0583b92-f0e8-491b-b790-d6ef98acc094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decode one step at a time\n",
    "t=0 #up to max_decode_step, which is 100 by default\n",
    "batch_list = [ bid for bid in range(batch_size) if len(stack[bid]) > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8be2ae81-69ce-40d9-b310-5b1bdb087938",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = batch_idx.new_tensor(batch_list)\n",
    "cur_tree_nodes = [stack[bid][-1] for bid in batch_list]\n",
    "subtree = batch_idx.new_tensor(cur_tree_nodes).cuda(), batch_idx.new_tensor([]).cuda()\n",
    "subgraph = batch_idx.new_tensor( tree_batch.get_cluster_nodes(cur_tree_nodes) ).cuda(), batch_idx.new_tensor( tree_batch.get_cluster_edges(cur_tree_nodes) ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fa03bc0-09c6-4325-81b0-4b53756a1762",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3342750/2719942479.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhinter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhinter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hgraph2graph/hgraph/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tree_tensors, inter_tensors, graph_tensors, htree, hinter, hgraph, subtree, subgraph)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0msub_graph_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sub_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#graph tensor is already embedded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mhgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_graph_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_graph_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hgraph2graph/hgraph/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensors, h, num_nodes, subset)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmess\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mnei_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_select_ND\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_hidden_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hgraph2graph/hgraph/rnn.py\u001b[0m in \u001b[0;36msparse_forward\u001b[0;34m(self, h, fmess, submess, bgraph)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mh_nei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_select_ND\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mc_nei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_select_ND\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0msub_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_nei\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_nei\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_scatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_scatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hgraph2graph/hgraph/rnn.py\u001b[0m in \u001b[0;36mLSTM\u001b[0;34m(self, x, h_nei, c_nei)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mh_sum_nei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_nei\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mx_expand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_nei\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_i\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_sum_nei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_o\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_sum_nei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_f\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_expand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_nei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)"
     ]
    }
   ],
   "source": [
    "htree, hinter, hgraph = hmpn(tree_tensors, tree_tensors, graph_tensors, htree, hinter, hgraph, subtree, subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64245212-3107-4f94-b26a-4879b2a702b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_graph_tensors = hmpn.get_sub_tensor(graph_tensors,subgraph)[:-1]\n",
    "# fnode, fmess, agraph, bgraph = sub_graph_tensors \n",
    "# subnode, submess = subgraph\n",
    "# # if len(submess) > 0: \n",
    "# #     h = hmpn.graph_encoder.rnn.sparse_forward(hgraph.mess, fmess, submess, bgraph)\n",
    "# atom_size = common_atom_vocab.size()\n",
    "# bond_size = len(MolGraph.BOND_LIST) + MolGraph.MAX_POS\n",
    "# rnn = LSTM(atom_size + bond_size, args.hidden_size, args.depthG)\n",
    "# bgraph\n",
    "# # h = rnn(fmess, bgraph)\n",
    "# h = torch.zeros(fmess.size(0), args.hidden_size, device=fmess.device)\n",
    "# c = torch.zeros(fmess.size(0), args.hidden_size, device=fmess.device)\n",
    "# mask = torch.ones(h.size(0), 1, device=h.device)\n",
    "# mask[0, 0] = 0 #first message is padding\n",
    "\n",
    "# for i in range(args.depthG):\n",
    "#     h_nei = index_select_ND(h, 0, bgraph)\n",
    "#     c_nei = index_select_ND(c, 0, bgraph)\n",
    "#     h,c = LSTM(fmess, h_nei, c_nei)\n",
    "#     h = h * mask\n",
    "#     c = c * mask\n",
    "# # h = rnn.get_hidden_state(h)\n",
    "# # h,c = h\n",
    "# # mask = h.new_ones(h.size(0)).scatter_(0, submess, 0)\n",
    "# # h = h * mask.unsqueeze(1)\n",
    "# # c = c * mask.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94d6fa62-fe87-4302-bd4d-4ffa96c47a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(args.depthG):\n",
    "    h_nei = index_select_ND(h, 0, bgraph)\n",
    "    c_nei = index_select_ND(c, 0, bgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b7de62-6037-424f-8ad0-467a8566f125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c2ef75-1716-49ed-af9e-8c24be380b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topo_score(self, src_tree_vecs, batch_idx, topo_vecs):\n",
    "    use_attention = False\n",
    "    if use_attention:\n",
    "        topo_cxt = self.attention(src_tree_vecs, batch_idx, topo_vecs, self.A_topo)\n",
    "    else:\n",
    "        topo_cxt = src_tree_vecs.index_select(index=batch_idx, dim=0)\n",
    "    return self.topoNN( torch.cat([topo_vecs, topo_cxt], dim=-1) ).squeeze(-1)\n",
    "topo_scores = get_topo_score(src_tree_vecs, batch_idx, htree.node.index_select(0, subtree[0]))\n",
    "topo_scores = torch.sigmoid(topo_scores)\n",
    "if greedy:\n",
    "    topo_preds = topo_scores.tolist()\n",
    "else:\n",
    "    topo_preds = torch.bernoulli(topo_scores).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98549e46-ca7f-4fbe-9876-99af93610098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hgraph-rdkit",
   "language": "python",
   "name": "hgraph-rdkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
