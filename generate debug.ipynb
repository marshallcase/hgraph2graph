{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63d3b480-7815-46ef-b03c-08224b3b9fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcase/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#generation debugging \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import networkx as nx\n",
    "import rdkit\n",
    "import math, random, sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "from hgraph import *\n",
    "from hgraph.inc_graph import *\n",
    "from hgraph.encoder import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0455dac4-291a-45fc-866a-f7fb2ced103c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC',\n",
       " 'CC(C)C',\n",
       " 'CC(C)O',\n",
       " 'CCC(=O)O',\n",
       " 'CCC(C)C',\n",
       " 'CCC(N)=O',\n",
       " 'CCC1=CC=C(O)C=C1',\n",
       " 'CCC1=CC=CC=C1',\n",
       " 'CCC1=CN=CN1',\n",
       " 'CCC1=CNC2=C1C=CC=C2',\n",
       " 'CCCC(=O)O',\n",
       " 'CCCC(N)=O',\n",
       " 'CCCCCN',\n",
       " 'CCCCNC(=N)N',\n",
       " 'CCCSC',\n",
       " 'CCO',\n",
       " 'CCSCC(=O)CSCC',\n",
       " 'CN1CCCC1C(=O)O',\n",
       " 'CN1CCCC1C=O',\n",
       " 'CNCC(=O)O',\n",
       " 'CNCC=O',\n",
       " 'NCC=O',\n",
       " 'O=CC1CCCN1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = '/home/marcase/hgraph2graph/data/chembl/cyclic_vocab_new.txt'\n",
    "vocab = [x.strip(\"\\r\\n \").split() for x in open(vocab)]\n",
    "vocab = PairVocab(vocab)\n",
    "vocab.vocab[21][0]\n",
    "vocab.hvocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f9a9fa1-eaf1-464f-9154-c30e01016f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcase/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    train = 'cyclic_preprocessed_new/'\n",
    "    vocab = vocab\n",
    "    save_dir = 'test/'\n",
    "    atom_vocab = common_atom_vocab\n",
    "    load_model = None\n",
    "    seed = 7\n",
    "    rnn_type = 'LSTM'\n",
    "    hidden_size=125\n",
    "    embed_size=250\n",
    "    batch_size=1\n",
    "    latent_size=32\n",
    "    depthT=15\n",
    "    depthG=15\n",
    "    diterT=1\n",
    "    diterG=3\n",
    "    dropout=0.0\n",
    "    lr = 1e-3\n",
    "    clip_norm=5.0\n",
    "    step_beta=0.001\n",
    "    max_beta=1.0\n",
    "    warmup=10000\n",
    "    kl_anneal_iter=2000\n",
    "    epoch=20\n",
    "    anneal_rate=0.9\n",
    "    anneal_iter=25000\n",
    "    print_iter=50\n",
    "    save_iter=5000\n",
    "    model = '/home/marcase/hgraph2graph/ckpt/cyclic_new2/model.ckpt.140000'\n",
    "    load_model = True\n",
    "    nsample = 1\n",
    "    max_nodes=200\n",
    "    max_edges=400\n",
    "    max_AA = 6\n",
    "    max_sub_nodes = 50\n",
    "    \n",
    "args=Args()\n",
    "\n",
    "model = HierVAE(args).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d9a34d9-479b-4303-bbaa-ae9c705687fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #Params: 1353K\n"
     ]
    }
   ],
   "source": [
    "print(\"Model #Params: %dK\" % (sum([x.nelement() for x in model.parameters()]) / 1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b4e45d0-a264-4137-afd6-3fc1f1464d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from generate\n",
    "model.load_state_dict(torch.load(args.model)[0])\n",
    "model.eval()\n",
    "torch.manual_seed(args.seed)\n",
    "random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ca51fbe-3cf4-4643-b4a0-559508d1519d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n",
      "(200, 38)\n",
      "Iteration: 0\n",
      "C.CNCC=O\n",
      "Most likely vocab elements to add: ['CNCC=O', 'NCC=O', 'CCO', 'CCCCCN', 'CN1CCCC1C=O']\n",
      "Amino acid #: 0\n",
      "Chosen vocab: CNCC=O\n",
      "Atom index of new attachment: [3]\n",
      "Iteration: 1\n",
      "C.CNC(C=O)NCC=O\n",
      "Most likely vocab elements to add: ['CNCC=O', 'NCC=O', 'CCO', 'CN1CCCC1C=O', 'CCC1=CN=CN1']\n",
      "Amino acid #: 1\n",
      "Chosen vocab: CNCC=O\n",
      "Atom index of new attachment: [8]\n",
      "Iteration: 2\n",
      "C.CNC(C=O)NC(C=O)NCC=O\n",
      "Most likely vocab elements to add: ['CNCC=O', 'CCO', 'CCCCNC(=N)N', 'CCCCCN', 'NCC=O']\n",
      "Amino acid #: 2\n",
      "Chosen vocab: CNCC=O\n",
      "Atom index of new attachment: [12]\n",
      "Iteration: 3\n",
      "C.CNC(C=O)NC(C=O)NC(C=O)NCC=O\n",
      "Most likely vocab elements to add: ['CNCC=O', 'CN1CCCC1C=O', 'CCO', 'NCC=O', 'CCC1=CC=C(O)C=C1']\n",
      "Amino acid #: 3\n",
      "Chosen vocab: CNCC=O\n",
      "Atom index of new attachment: [16]\n",
      "Iteration: 4\n",
      "C.CNC(C=O)NC(C=O)NC(C=O)NC(C=O)NCC=O\n",
      "Most likely vocab elements to add: ['CN1CCCC1C=O', 'CNCC=O', 'CCO', 'NCC=O', 'CCC1=CC=C(O)C=C1']\n",
      "Amino acid #: 4\n",
      "Chosen vocab: CN1CCCC1C=O\n",
      "Atom index of new attachment: [20]\n",
      "Iteration: 5\n",
      "C.CNC(C=O)NC(C=O)NC(C=O)NC(C=O)NC(C=O)N1CCCC1C=O\n",
      "Most likely vocab elements to add: ['CNCC=O', 'CN1CCCC1C=O', 'CCO', 'CCCCCN', 'CCCCNC(=N)N']\n",
      "Amino acid #: 5\n",
      "Chosen vocab: CNCC=O\n",
      "Atom index of new attachment: [24]\n",
      "Iteration: 6\n",
      "C.CNC(C=O)NC(C=O)NC(C=O)NC(C=O)NC(C=O)N1CCCC1(C=O)NCC=O\n",
      "Most likely vocab elements to add: ['CNCC=O', 'CCO', 'NCC=O', 'CN1CCCC1C=O', 'CCCCCN']\n",
      "Amino acid #: 6\n",
      "Chosen vocab: CNCC=O\n",
      "Atom index of new attachment: [31]\n",
      "Iteration: 7\n",
      "C.CNC(C=O)NC(C=O)NC(C=O)NC(C=O)NC(C=O)N1CCCC1(C=O)NC(C=O)NCC=O\n",
      "Most likely vocab elements to add: ['CNCC=O', 'CN1CCCC1C(=O)O', 'NCC=O', 'CNCC(=O)O', 'CN1CCCC1C=O']\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Iteration: 8\n",
      "C.CNC(C=O)NC(C=O)NC(C=O)NC(C=O)NC(C=O)N1CCCC1(C=O)NC(C=O)NCC=O\n",
      "Most likely vocab elements to add: ['CNCC=O', 'CCO', 'NCC=O', 'CN1CCCC1C=O', 'CCCCCN']\n",
      "Trying to add AA when max AA reached\n",
      "Chosen vocab: CCO\n",
      "Atom index of new attachment: [30]\n",
      "Iteration: 9\n",
      "C.CNC(C=O)NC(C=O)NC(C=O)NC(C=O)NC(C=O)N1CCCC1(C=O)NC(NCC=O)C(=O)CO\n",
      "Most likely vocab elements to add: ['CNCC=O', 'CCO', 'CCCCCN', 'CCCC(N)=O', 'CCC1=CC=C(O)C=C1']\n",
      "Trying to add AA when max AA reached\n",
      "Chosen vocab: CCO\n",
      "Atom index of new attachment: [38]\n",
      "Iteration: 10\n",
      "C.CNC(C=O)NC(C=O)NC(C=O)NC(C=O)NC(C=O)N1CCCC1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Iteration: 11\n",
      "C.CNC(C=O)NC(C=O)NC(C=O)NC(C=O)NC(C=O)N1CCCC1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Iteration: 12\n",
      "C.CNC(C=O)NC(C=O)NC(C=O)NC(C=O)NC(C=O)N1CCCC1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Iteration: 13\n",
      "C.CNC(C=O)NC(C=O)NC(C=O)NC(C=O)NC(C=O)N1CCCC1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Most likely vocab elements to add: ['CCSCC(=O)CSCC', 'CCCC(N)=O', 'CCO', 'CNCC=O', 'CCCCCN']\n",
      "Stapled residue. TODO: connect them\n",
      "Chosen vocab: CCSCC(=O)CSCC\n",
      "Atom index of new attachment: [25]\n",
      "Iteration: 14\n",
      "C.CCSCC(=O)CSCC1CCN(C(C=O)NC(C=O)NC(C=O)NC(C=O)NC(C=O)NC)C1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Most likely vocab elements to add: ['CNCC=O', 'CNCC=O', 'CCCC(N)=O', 'CNCC=O', 'CNCC(=O)O']\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Chosen vocab: CCCC(N)=O\n",
      "Atom index of new attachment: [44]\n",
      "Iteration: 15\n",
      "C.CCSC(CCC(N)=O)C(=O)CSCC1CCN(C(C=O)NC(C=O)NC(C=O)NC(C=O)NC(C=O)NC)C1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Iteration: 16\n",
      "C.CCSC(CCC(N)=O)C(=O)CSCC1CCN(C(C=O)NC(C=O)NC(C=O)NC(C=O)NC(C=O)NC)C1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Iteration: 17\n",
      "C.CCSC(CCC(N)=O)C(=O)CSCC1CCN(C(C=O)NC(C=O)NC(C=O)NC(C=O)NC(C=O)NC)C1(C=O)NC(NCC=O)C(=O)C(O)CO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 18\n",
      "C.CCSC(CCC(N)=O)C(=O)CSCC1CCN(C(C=O)NC(C=O)NC(C=O)NC(C=O)NC(C=O)NC)C1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Most likely vocab elements to add: ['CCO', 'CCCCCN', 'CCSCC(=O)CSCC', 'CCC1=CNC2=C1C=CC=C2', 'CCCC(N)=O']\n",
      "Chosen vocab: CCO\n",
      "Atom index of new attachment: [19]\n",
      "Iteration: 19\n",
      "C.CCSC(CCC(N)=O)C(=O)CSCC1CCN(C(NC(C=O)NC(C=O)NC(C=O)NC(C=O)NC)C(=O)CO)C1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Iteration: 20\n",
      "C.CCSC(CCC(N)=O)C(=O)CSCC1CCN(C(NC(C=O)NC(C=O)NC(C=O)NC(C=O)NC)C(=O)CO)C1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Iteration: 21\n",
      "C.CCSC(CCC(N)=O)C(=O)CSCC1CCN(C(NC(C=O)NC(C=O)NC(C=O)NC(C=O)NC)C(=O)CO)C1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Iteration: 22\n",
      "C.CCSC(CCC(N)=O)C(=O)CSCC1CCN(C(NC(C=O)NC(C=O)NC(C=O)NC(C=O)NC)C(=O)CO)C1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Most likely vocab elements to add: ['CCCCNC(=N)N', 'CCCCCN', 'CCC1=CNC2=C1C=CC=C2', 'CCSCC(=O)CSCC', 'CCCC(N)=O']\n",
      "Chosen vocab: CCCCNC(=N)N\n",
      "Atom index of new attachment: [11]\n",
      "Iteration: 23\n",
      "C.CCSC(CCC(N)=O)C(=O)CSCC1CCN(C(NC(C=O)NC(NC(C=O)NC(C=O)NC)C(=O)CCCNC(=N)N)C(=O)CO)C1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Iteration: 24\n",
      "C.CCSC(CCC(N)=O)C(=O)CSCC1CCN(C(NC(C=O)NC(NC(C=O)NC(C=O)NC)C(=O)CCCNC(=N)N)C(=O)CO)C1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Iteration: 25\n",
      "C.CCSC(CCC(N)=O)C(=O)CSCC1CCN(C(NC(C=O)NC(NC(C=O)NC(C=O)NC)C(=O)CCCNC(=N)N)C(=O)CO)C1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Most likely vocab elements to add: ['CCCCCN', 'CCC1=CN=CN1', 'CCC1=CNC2=C1C=CC=C2', 'CCC1=CC=C(O)C=C1', 'CCCC(N)=O']\n",
      "Chosen vocab: CCCCCN\n",
      "Atom index of new attachment: [7]\n",
      "Iteration: 26\n",
      "C.CCSC(CCC(N)=O)C(=O)CSCC1CCN(C(NC(C=O)NC(NC(NC(C=O)NC)C(=O)CCCCN)C(=O)CCCNC(=N)N)C(=O)CO)C1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Iteration: 27\n",
      "C.CCSC(CCC(N)=O)C(=O)CSCC1CCN(C(NC(C=O)NC(NC(NC(C=O)NC)C(=O)CCCCN)C(=O)CCCNC(=N)N)C(=O)CO)C1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Iteration: 28\n",
      "C.CCSC(CCC(N)=O)C(=O)CSCC1CCN(C(NC(C=O)NC(NC(NC(C=O)NC)C(=O)CCCCN)C(=O)CCCNC(=N)N)C(=O)CO)C1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Most likely vocab elements to add: ['NCC=O', 'CNCC=O', 'CCCCCN', 'CN1CCCC1C=O', 'CCC1=CC=C(O)C=C1']\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Chosen vocab: CCCCCN\n",
      "Atom index of new attachment: [4]\n",
      "Iteration: 29\n",
      "C.CCSC(CCC(N)=O)C(=O)CSCC1CCN(C(NC(C=O)NC(NC(NC(NC)C(=O)CCCCN)C(=O)CCCCN)C(=O)CCCNC(=N)N)C(=O)CO)C1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Iteration: 30\n",
      "C.CCSC(CCC(N)=O)C(=O)CSCC1CCN(C(NC(C=O)NC(NC(NC(NC)C(=O)CCCCN)C(=O)CCCCN)C(=O)CCCNC(=N)N)C(=O)CO)C1(C=O)NC(NCC=O)C(=O)C(O)CO\n",
      "Most likely vocab elements to add: ['CCSCC(=O)CSCC', 'CCC1=CC=C(O)C=C1', 'CN1CCCC1C=O', 'CN1CCCC1C=O', 'NCC=O']\n",
      "Stapled residue. TODO: connect them\n",
      "Chosen vocab: CCSCC(=O)CSCC\n",
      "Atom index of new attachment: [1]\n",
      "Iteration: 31\n",
      "C.CCSCC(=O)CSCCNC(NC(NC(NC(C=O)NC(C(=O)CO)N1CCC(CSCC(=O)C(CCC(N)=O)SCC)C1(C=O)NC(NCC=O)C(=O)C(O)CO)C(=O)CCCNC(=N)N)C(=O)CCCCN)C(=O)CCCCN\n",
      "Most likely vocab elements to add: ['CNCC=O', 'NCC=O', 'CNCC=O', 'CNCC=O', 'CNCC(=O)O']\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n",
      "Trying to add AA when max AA reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2991745/3621716190.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnsample\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0msmiles_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreedy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_edges\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_AA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/hgraph2graph/hgraph/hgnn.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, batch_size, greedy, max_nodes, max_edges, max_sub_nodes, max_decode_step, max_AA)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mroot_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         return self.decoder.decode((root_vecs, root_vecs, root_vecs), greedy=greedy,\n\u001b[0;32m---> 45\u001b[0;31m                                    max_decode_step=max_decode_step,max_AA=max_AA)\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hgraph2graph/hgraph/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, src_mol_vecs, greedy, beam, max_nodes, max_edges, max_sub_nodes, max_decode_step, max_AA)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0;31m#anchor_smiles: smiles string of the node from where the new node is being attached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;31m#attach_points: ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                     \u001b[0minter_cands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchor_smiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattach_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_assm_cands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfa_cluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfa_used\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mismiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minter_cands\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hgraph2graph/hgraph/inc_graph.py\u001b[0m in \u001b[0;36mget_assm_cands\u001b[0;34m(self, cluster, used, smiles)\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattach_points\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_anchor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetAtomWithIdx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#all attach points are labeled with 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mattach_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattach_points\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mattach_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattach_points\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#force the attach_points to be a chain like anchor ... anchor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0manchor_smiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_anchor_smiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for _ in tqdm(range(args.nsample // args.batch_size)):\n",
    "        smiles_list = model.sample(args.batch_size, greedy=True,max_nodes=200,max_edges=400,max_AA=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be0608da-2c68-47b1-9294-a446d237caef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.vocab.is_backbone_hvocab('CN1CCCC1C=O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bfdb59-8732-496e-83b9-d93d460624b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = range(args.epoch)[0]\n",
    "dataset = DataFolder(args.train,args.batch_size)\n",
    "for param in model.parameters():\n",
    "    # print(param)\n",
    "    1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19b1efca-def5-46a5-a296-3b0b094d4d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #begin training the model\n",
    "# for batch in tqdm(dataset):\n",
    "#     total_step += 1\n",
    "#     model.zero_grad()\n",
    "#     loss, kl_div, wacc, iacc, tacc, sacc = model(*batch, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5749de5f-58f0-4378-bdb1-60f2c4ff90d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file0 = os.path.join(dataset.data_folder,'tensors-0.pkl')\n",
    "with open(data_file0,'rb') as f:\n",
    "    batches = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ee826d-e94f-45ea-bd95-095069659867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.9945, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 42.87664031982422,\n",
       " tensor(0.9921, device='cuda:0'),\n",
       " tensor(1., device='cuda:0'),\n",
       " tensor(1., device='cuda:0'),\n",
       " tensor(1., device='cuda:0'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(*batches[0],beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dce7bb9-2526-45fd-b4b1-349f6baf5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.draw(batches[0][0][1])\n",
    "# plt.show()\n",
    "\n",
    "#just realized I have no idea what format the tensorized molecules are in. let's go back and check the tensorize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db527a00-e43f-40e1-b078-78bd871a51bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from model.sample()\n",
    "batch_size = args.batch_size\n",
    "latent_size = args.latent_size\n",
    "root_vecs = torch.randn(batch_size, latent_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eedd6972-2e97-47b5-ac8e-694671bcc5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from HierMPNDecoder.decode()\n",
    "src_root_vecs, src_tree_vecs, src_graph_vecs = root_vecs,root_vecs,root_vecs\n",
    "batch_size = len(src_root_vecs)\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34b97185-7dbf-4225-ab34-86aea505ad62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "tree_batch = IncTree(batch_size, node_fdim=2, edge_fdim=3)\n",
    "# nx.draw(tree_batch.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c02e0261-8a50-444e-b338-cd3072969e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmpn = IncHierMPNEncoder(args.vocab, args.atom_vocab, args.rnn_type, args.embed_size, args.hidden_size, args.depthT, args.depthG, args.dropout)\n",
    "test = hmpn.tree_encoder\n",
    "test.depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36d9cad5-5b11-44ff-acc6-f34085d6b117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 38)\n"
     ]
    }
   ],
   "source": [
    "graph_batch = IncGraph(args.atom_vocab, batch_size, node_fdim=hmpn.atom_size, edge_fdim=hmpn.atom_size + hmpn.bond_size)\n",
    "# nx.draw(graph_batch.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "983cb9b1-a89e-4689-a1a3-1dd01d29e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cls_score(src_tree_vecs, batch_idx, cls_vecs, cls_labs):\n",
    "    use_attention = False\n",
    "    if use_attention:\n",
    "        cls_cxt = self.attention(src_tree_vecs, batch_idx, cls_vecs, self.A_cls)\n",
    "    else:\n",
    "        cls_cxt = src_tree_vecs.index_select(index=batch_idx, dim=0).cuda()\n",
    "\n",
    "    cls_vecs = torch.cat([cls_vecs, cls_cxt], dim=-1).cuda()\n",
    "    clsNN = nn.Sequential(\n",
    "                nn.Linear(args.hidden_size + args.latent_size, args.hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(args.dropout),\n",
    "                nn.Linear(args.hidden_size, args.vocab.size()[0])\n",
    "        ).cuda()\n",
    "    iclsNN = nn.Sequential(\n",
    "                nn.Linear(args.hidden_size + args.latent_size, args.hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(args.dropout),\n",
    "                nn.Linear(args.hidden_size, args.vocab.size()[1])\n",
    "        ).cuda()\n",
    "    cls_scores = clsNN(cls_vecs)\n",
    "\n",
    "    if cls_labs is None: #inference mode\n",
    "        icls_scores = iclsNN(cls_vecs) #no masking\n",
    "    else:\n",
    "        vocab_masks = args.vocab.get_mask(cls_labs)\n",
    "        icls_scores = iclsNN(cls_vecs) + vocab_masks #apply mask by log(x + mask): mask=0 or -INF\n",
    "    return cls_scores, icls_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00d1b1b5-c598-46df-8f67-48c0a5a9299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = [[] for i in range(batch_size)]\n",
    "W_root = nn.Linear(args.latent_size, args.hidden_size).cuda()\n",
    "init_vecs = src_root_vecs if args.latent_size == args.hidden_size else W_root(src_root_vecs)\n",
    "itensor = torch.LongTensor([]).cuda()\n",
    "batch_idx = itensor.new_tensor(range(batch_size))\n",
    "cls_scores, icls_scores = get_cls_score(src_tree_vecs, batch_idx, init_vecs, None)\n",
    "root_cls = cls_scores.max(dim=-1)[1]\n",
    "icls_scores = icls_scores + args.vocab.get_mask(root_cls)\n",
    "root_cls, root_icls = root_cls.tolist(), icls_scores.max(dim=-1)[1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d38035ac-5978-489e-82b9-33d9ce2add2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "super_root = tree_batch.add_node() \n",
    "for bid in range(batch_size):\n",
    "    clab, ilab = root_cls[bid], root_icls[bid]\n",
    "    root_idx = tree_batch.add_node( batch_idx.new_tensor([clab, ilab]) )\n",
    "    tree_batch.add_edge(super_root, root_idx) \n",
    "    stack[bid].append(root_idx)\n",
    "\n",
    "    root_smiles = args.vocab.get_ismiles(ilab)\n",
    "    new_atoms, new_bonds, attached = graph_batch.add_mol(bid, root_smiles, [], 0)\n",
    "    tree_batch.register_cgraph(root_idx, new_atoms, new_bonds, attached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1819a370-d1b5-40d7-9853-52f88a630aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.draw(tree_batch.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0c42b7c-4732-49c4-80cf-ea20df1bf641",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HTuple():\n",
    "    def __init__(self, node=None, mess=None, vmask=None, emask=None):\n",
    "        self.node, self.mess = node, mess\n",
    "        self.vmask, self.emask = vmask, emask\n",
    "#invariance: tree_tensors is equal to inter_tensors (but inter_tensor's init_vec is 0)\n",
    "tree_tensors = tree_batch.get_tensors()\n",
    "graph_tensors = graph_batch.get_tensors()\n",
    "\n",
    "htree = HTuple( mess = hmpn.tree_encoder.rnn.get_init_state(tree_tensors[1]) )\n",
    "hinter = HTuple( mess = hmpn.tree_encoder.rnn.get_init_state(tree_tensors[1]) )\n",
    "hgraph = HTuple( mess = hmpn.tree_encoder.rnn.get_init_state(graph_tensors[1]) )\n",
    "h = hmpn.tree_encoder.rnn.get_hidden_state(htree.mess)\n",
    "h[1 : batch_size + 1] = init_vecs #wiring root (only for tree, not inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0583b92-f0e8-491b-b790-d6ef98acc094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decode one step at a time\n",
    "t=0 #up to max_decode_step, which is 100 by default\n",
    "batch_list = [ bid for bid in range(batch_size) if len(stack[bid]) > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8be2ae81-69ce-40d9-b310-5b1bdb087938",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = batch_idx.new_tensor(batch_list)\n",
    "cur_tree_nodes = [stack[bid][-1] for bid in batch_list]\n",
    "subtree = batch_idx.new_tensor(cur_tree_nodes).cuda(), batch_idx.new_tensor([]).cuda()\n",
    "subgraph = batch_idx.new_tensor( tree_batch.get_cluster_nodes(cur_tree_nodes) ).cuda(), batch_idx.new_tensor( tree_batch.get_cluster_edges(cur_tree_nodes) ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fa03bc0-09c6-4325-81b0-4b53756a1762",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3342750/2719942479.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhinter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhinter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hgraph2graph/hgraph/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tree_tensors, inter_tensors, graph_tensors, htree, hinter, hgraph, subtree, subgraph)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0msub_graph_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sub_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#graph tensor is already embedded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mhgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_graph_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_graph_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hgraph2graph/hgraph/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensors, h, num_nodes, subset)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmess\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mnei_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_select_ND\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_hidden_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hgraph2graph/hgraph/rnn.py\u001b[0m in \u001b[0;36msparse_forward\u001b[0;34m(self, h, fmess, submess, bgraph)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mh_nei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_select_ND\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mc_nei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_select_ND\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0msub_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_nei\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_nei\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_scatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_scatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hgraph2graph/hgraph/rnn.py\u001b[0m in \u001b[0;36mLSTM\u001b[0;34m(self, x, h_nei, c_nei)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mh_sum_nei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_nei\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mx_expand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_nei\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_i\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_sum_nei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_o\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_sum_nei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_f\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_expand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_nei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hgraph-rdkit/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)"
     ]
    }
   ],
   "source": [
    "htree, hinter, hgraph = hmpn(tree_tensors, tree_tensors, graph_tensors, htree, hinter, hgraph, subtree, subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64245212-3107-4f94-b26a-4879b2a702b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_graph_tensors = hmpn.get_sub_tensor(graph_tensors,subgraph)[:-1]\n",
    "# fnode, fmess, agraph, bgraph = sub_graph_tensors \n",
    "# subnode, submess = subgraph\n",
    "# # if len(submess) > 0: \n",
    "# #     h = hmpn.graph_encoder.rnn.sparse_forward(hgraph.mess, fmess, submess, bgraph)\n",
    "# atom_size = common_atom_vocab.size()\n",
    "# bond_size = len(MolGraph.BOND_LIST) + MolGraph.MAX_POS\n",
    "# rnn = LSTM(atom_size + bond_size, args.hidden_size, args.depthG)\n",
    "# bgraph\n",
    "# # h = rnn(fmess, bgraph)\n",
    "# h = torch.zeros(fmess.size(0), args.hidden_size, device=fmess.device)\n",
    "# c = torch.zeros(fmess.size(0), args.hidden_size, device=fmess.device)\n",
    "# mask = torch.ones(h.size(0), 1, device=h.device)\n",
    "# mask[0, 0] = 0 #first message is padding\n",
    "\n",
    "# for i in range(args.depthG):\n",
    "#     h_nei = index_select_ND(h, 0, bgraph)\n",
    "#     c_nei = index_select_ND(c, 0, bgraph)\n",
    "#     h,c = LSTM(fmess, h_nei, c_nei)\n",
    "#     h = h * mask\n",
    "#     c = c * mask\n",
    "# # h = rnn.get_hidden_state(h)\n",
    "# # h,c = h\n",
    "# # mask = h.new_ones(h.size(0)).scatter_(0, submess, 0)\n",
    "# # h = h * mask.unsqueeze(1)\n",
    "# # c = c * mask.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94d6fa62-fe87-4302-bd4d-4ffa96c47a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(args.depthG):\n",
    "    h_nei = index_select_ND(h, 0, bgraph)\n",
    "    c_nei = index_select_ND(c, 0, bgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b7de62-6037-424f-8ad0-467a8566f125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c2ef75-1716-49ed-af9e-8c24be380b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topo_score(self, src_tree_vecs, batch_idx, topo_vecs):\n",
    "    use_attention = False\n",
    "    if use_attention:\n",
    "        topo_cxt = self.attention(src_tree_vecs, batch_idx, topo_vecs, self.A_topo)\n",
    "    else:\n",
    "        topo_cxt = src_tree_vecs.index_select(index=batch_idx, dim=0)\n",
    "    return self.topoNN( torch.cat([topo_vecs, topo_cxt], dim=-1) ).squeeze(-1)\n",
    "topo_scores = get_topo_score(src_tree_vecs, batch_idx, htree.node.index_select(0, subtree[0]))\n",
    "topo_scores = torch.sigmoid(topo_scores)\n",
    "if greedy:\n",
    "    topo_preds = topo_scores.tolist()\n",
    "else:\n",
    "    topo_preds = torch.bernoulli(topo_scores).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98549e46-ca7f-4fbe-9876-99af93610098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hgraph-rdkit",
   "language": "python",
   "name": "hgraph-rdkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
